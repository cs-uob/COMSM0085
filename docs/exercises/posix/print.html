<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Exercises</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="act1/index.html"><strong aria-hidden="true">1.</strong> Activity 1</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="act1/ssh.html"><strong aria-hidden="true">1.1.</strong> Secure shell</a></li><li class="chapter-item expanded "><a href="act1/install.html"><strong aria-hidden="true">1.2.</strong> Installing vagrant and alpine linux</a></li><li class="chapter-item expanded "><a href="act1/admin.html"><strong aria-hidden="true">1.3.</strong> Alpine linux system administration</a></li><li class="chapter-item expanded "><a href="act1/shell.html"><strong aria-hidden="true">1.4.</strong> Shell expansion</a></li><li class="chapter-item expanded "><a href="act1/git1.html"><strong aria-hidden="true">1.5.</strong> Git, part 1</a></li></ol></li><li class="chapter-item expanded "><a href="act2/index.html"><strong aria-hidden="true">2.</strong> Activity 2</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="act2/permissions.html"><strong aria-hidden="true">2.1.</strong> File permissions</a></li><li class="chapter-item expanded "><a href="act2/git2.html"><strong aria-hidden="true">2.2.</strong> Git, part 2</a></li><li class="chapter-item expanded "><a href="act2/pipes.html"><strong aria-hidden="true">2.3.</strong> Pipes</a></li></ol></li><li class="chapter-item expanded "><a href="act3/index.html"><strong aria-hidden="true">3.</strong> Activity 3</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="act3/git3.html"><strong aria-hidden="true">3.1.</strong> Git, part 3</a></li><li class="chapter-item expanded "><a href="act3/stat.html"><strong aria-hidden="true">3.2.</strong> inodes and system calls</a></li><li class="chapter-item expanded "><a href="act3/script.html"><strong aria-hidden="true">3.3.</strong> shell scripting</a></li></ol></li><li class="chapter-item expanded "><a href="act4/index.html"><strong aria-hidden="true">4.</strong> Activity 4</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="act4/concurrent.html"><strong aria-hidden="true">4.1.</strong> Concurrent programming in POSIX</a></li><li class="chapter-item expanded "><a href="act4/cpipe.html"><strong aria-hidden="true">4.2.</strong> Pipes in C</a></li><li class="chapter-item expanded "><a href="act4/c_io.html"><strong aria-hidden="true">4.3.</strong> Input/Output in C</a></li><li class="chapter-item expanded "><a href="act4/posix_io.html"><strong aria-hidden="true">4.4.</strong> Input/Output in POSIX</a></li><li class="chapter-item expanded "><a href="act4/final.html"><strong aria-hidden="true">4.5.</strong> The final challenge</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Exercises</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#activity-1" id="activity-1">Activity 1</a></h1>
<h2><a class="header" href="#videos" id="videos">Videos</a></h2>
<p>Before this activity, you should watch the following videos - most of them are quite short. The first link to each one links directly to an <code>.mp4</code> file that you can, for example, download and watch on your own machine. The second link takes you to the mediasite player which streams the video and provides optional captions, but you must be registered on the unit and logged in to blackboard to use the mediasite player link.</p>
<table><thead><tr><th>Video</th><th align="right">Length</th><th>Mediasite</th><th>Slides</th></tr></thead><tbody>
<tr><td><a href="https://ams-hsta-ims-ond.mediasite.com/MediasiteDeliver/vol01/bristoluniversity/MP4Video/ee98529d-3900-4efb-ac94-d2e0d951e533.mp4/QualityLevels(698000)">shell</a></td><td align="right">19 minutes</td><td><a href="https://mediasite.bris.ac.uk/Mediasite/Play/165af898778b4b06a141ab6196124f8b1d">mediasite</a></td><td><a href="act1//COMS10012/slides/shell.pdf">slides</a></td></tr>
<tr><td><a href="https://ams-hsta-ims-ond.mediasite.com/MediasiteDeliver/vol01/bristoluniversity/MP4Video/819aeecb-f5a6-47b9-9d22-306ade265b6b.mp4/QualityLevels(698000)">SSH</a></td><td align="right">7 minutes</td><td><a href="https://mediasite.bris.ac.uk/Mediasite/Play/e183094b765e45879ad085da62041ab51d">mediasite</a></td><td><a href="act1//COMS10012/slides/SSH.pdf">slides</a></td></tr>
<tr><td><a href="https://ams-hsta-ims-ond.mediasite.com/MediasiteDeliver/vol01/bristoluniversity/MP4Video/c771016a-8101-4236-b53a-dd2bb340eec3.mp4/QualityLevels(698000)">Vagrant</a></td><td align="right">33 minutes</td><td><a href="https://mediasite.bris.ac.uk/Mediasite/Play/82ae82e2e9324dbeb37bc4983a03d2941d">mediasite</a></td><td><a href="act1//COMS10012/slides/Vagrant.pdf">slides</a></td></tr>
<tr><td><a href="https://ams-hsta-ims-ond.mediasite.com/MediasiteDeliver/vol01/bristoluniversity/MP4Video/32f7121e-3bd3-4516-9de1-c8de4355fcf8.mp4/QualityLevels(698000)">Package managers</a></td><td align="right">12 minutes</td><td><a href="https://mediasite.bris.ac.uk/Mediasite/Play/e43dd6c0a3f94990bf712435f23310b31d">mediasite</a></td><td><a href="act1//COMS10012/slides/Package%20managers.pdf">slides</a></td></tr>
<tr><td><a href="https://ams-hsta-ims-ond.mediasite.com/MediasiteDeliver/vol01/bristoluniversity/MP4Video/8703ab2e-f791-4ab0-bef6-262a91069b4c.mp4/QualityLevels(698000)">Git 1</a></td><td align="right">21 minutes</td><td><a href="https://mediasite.bris.ac.uk/Mediasite/Play/c85056040c3b4f34b762901b1ad9360c1d">mediasite</a></td><td><a href="act1//COMS10012/slides/Git%201.pdf">slides</a></td></tr>
</tbody></table>
<h2><a class="header" href="#exercises" id="exercises">Exercises</a></h2>
<ul>
<li><a href="act1/./ssh.html">Secure shell</a></li>
<li><a href="act1/./install.html">Installing vagrant and alpine linux</a></li>
<li><a href="act1/./admin.html">Alpine linux system administration</a></li>
<li><a href="act1/./shell.html">Shell expansion</a></li>
<li><a href="act1/./git1.html">Git, part 1</a></li>
</ul>
<h1><a class="header" href="#secure-shell" id="secure-shell">Secure shell</a></h1>
<p>Secure shell (SSH) is a protocol to allow you to remotely log in to another computer, such as a lab machine. Everyone I know of who uses SSH uses the free OpenSSH implementation, which is standard on every linux distribution that I know of and is also available for Windows and Mac - and even for the mobile operating systems iOS and Android.</p>
<p>We will see in more detail how SSH manages connections later on, but for now imagine that it opens a network connection between your own machine, and a shell running on a different machine. When you type something, SSH encrypts this and sends it to the other machine which decrypts it and passes it to the shell (or any other program you're running); when the shell replies then SSH encrypts that and sends it back to you. For this to work, (Open)SSH is actually two programs:</p>
<ul>
<li><code>ssh</code> is the client, which you run on your machine to connect to another machine.</li>
<li><code>sshd</code> is the server, or <em>daemon</em> in UNIX-speak. It runs in the background on the machine you want to connect to, and needs to be installed by the system administrator.</li>
</ul>
<div class="advanced container">
<header><span class="advanced-title"></span></header>
<div class="container-content">
<p>SSH uses TCP port 22 by default.</p>
</div>
</div>
<h2><a class="header" href="#check-your-client" id="check-your-client">Check your client</a></h2>
<p>First of all, let's check that the ssh client is working.</p>
<ul>
<li>Open a terminal on your own machine: linux, mac OS and windows subsystem for linux should be fine. Windows 10 CMD might work too if you have the windows version of openssh installed (for example if you have git installed which uses ssh behind the scenes).</li>
<li>Type <code>ssh localhost</code> and press ENTER. Several different things could happen:
<ul>
<li>If it asks for a password, then the ssh client is working, and a ssh server is running on your current machine. The password would be your user account password, but we don't actually want to log in again so cancel with Control+C.</li>
<li>If it succeeds without a password, then the client is working and a ssh server is running on your machine and either you do not have a password, or you already have a key set up. Type <code>exit</code> and press ENTER to get back to your previous shell.</li>
<li>If it shows &quot;connection refused&quot;, then you have the ssh client correctly working but no server running on your own machine. This is not a problem, as we're trying to log in to the lab machines, so we need a client on our machine and a server on the lab machine.</li>
<li>If it shows an error that ssh is not found, then you don't have (Open)SSH installed which is very unusual except on windows CMD - in which case please switch to using the windows subsystem for linux.</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#connect-to-the-lab" id="connect-to-the-lab">Connect to the lab</a></h2>
<p>The lab machines have names <code>it######.wks.bris.ac.uk</code> where the hashes represent a number from 075637 up to 075912. However, not all of them will be working at any one time, if everyone connects to the same machine then it will quickly get overloaded, and for security reasons the lab machines are not directly accessible from the internet. Instead, we will use two other machines to connect:</p>
<ul>
<li>The bastion host <code>seis.bris.ac.uk</code>. This is reachable over SSH from the internet, and is on a university network that lets you connect further to the lab machines. You should not attempt to do any work on seis itself, as most of the software you would like to use (like compilers) is not installed there. However, you do have a home directory on seis for storing things like SSH keys.</li>
<li>The load balancer <code>rd-mvb-linuxlab.bristol.ac.uk</code>. This connects you to a lab machine that is currently running and ensures that if everyone uses this method to connect, then they will be more or less equally distributed among the running machines.</li>
</ul>
<p>Try the following:</p>
<ul>
<li>On your terminal, type <code>ssh USERNAME@seis.bris.ac.uk</code> where you replace USERNAME with your university username, e.g. <code>aa20123</code>. Obviously, you will need a working internet connection for this.</li>
<li>If it asks you whether you are sure, type <code>yes</code> and press ENTER. SSH will only do this the first time you connect to a machine that you have never used before.</li>
<li>When prompted, enter your university password and press ENTER.</li>
<li>You should now see the prompt on seis, which looks something like <code>-bash-4.2$</code>. Try the command <code>uname -a</code> to print information about the system (uname on its own prints the operating system name, <code>-a</code> shows &quot;all&quot; information). The reply line should start <code>Linux seis-shell</code>, which is the operating system and host name.</li>
<li>On the seis prompt, type <code>ssh rd-mvb-linuxlab.bristol.ac.uk</code>. This might take a few seconds; say yes if it asks you if you're sure, then enter your password again when prompted. We didn't have to give a username again because you are already logged in to seis with your university username (<code>whoami</code> shows this) and when you ssh without giving a username, it uses the one you are currently logged in as.</li>
<li>You should now be connected to a lab machine, with a prompt of the form <code>USERNAME@it######:~$</code>. </li>
<li>Try <code>whoami</code> and <code>uname -a</code> to check who you are logged in as, and where; also try <code>hostname</code> which just prints the machine name.</li>
<li>Type <code>exit</code> twice to get back to your own machine. (Once gets you back to seis, twice closes the ssh connection completely.)</li>
</ul>
<p>Connecting to one machine through another machine (in this case seis) as a proxy is such a common use case that ssh in fact has an option for it. Note however that this will not normally work from a windows CMD terminal, although it does work on Windows Subsystem for Linux (and on Mac and Linux).</p>
<pre><code>ssh -J USERNAME@seis.bris.ac.uk USERNAME@rd-mvb-linuxlab.bristol.ac.uk
</code></pre>
<p>The <code>-J</code> for &quot;jump through this host&quot; even accepts a comma-separated list of hosts if you need to connect through more than one. However, you need to repeat your username for every machine.</p>
<p>You now know how to log in to a lab machine, but in both methods you had to type your password twice - let's make that easier. The answer is not to store your password in a file, but to use keys instead.</p>
<h2><a class="header" href="#setting-up-ssh-keys" id="setting-up-ssh-keys">Setting up ssh keys</a></h2>
<p>When you connect to a machine, the client on your computer and the daemon on the machine you're logging in to run a cryptographic protocol to exchange keys and set up a shared secret key for the session, so that what one side encrypts the other side can decrypt again. It also authenticates you to the server using one of several methods. </p>
<p>You might have heard from a security source that there are three main authentication factors: something you know (password or PIN), something you have (physical key, digital key, ID card, passport) and something you are (biometrics). An authentication method that requires two of these is called two-factor authentication and this is considered good security practice. For ssh, this means:</p>
<ul>
<li>You can log in with a username and password, that is &quot;something you know&quot;. This is the default, but not the most secure.</li>
<li>You can log in with a (digital) key, that is &quot;something you have&quot;. This is more secure, as long as your key (which is just a file) doesn't get into the wrong hands, and also the most convenient as you can log into a lab machine or copy files without having to type your password.</li>
<li>You can log in with a key file that is itself protected with a password. This gets you two-factor authentication.</li>
</ul>
<p>The keys that SSH uses implement digital signatures. Each key comes as a pair of files:</p>
<ul>
<li>A private key (also known as secret key) in a file normally named <code>id_CIPHER</code> where CIPHER is the cipher in use. You need to keep this secure and only store it in places that only you have access to.</li>
<li>A public key in a file normally named <code>id_CIPHER.pub</code>. You can share this with the world, and you will need to store a copy of it on any machine or with any service that you want to log in to (for the lab, because the lab machines all share a file system, you only need to store it once - but seis has a separate file system so you need a separate copy there).</li>
</ul>
<p>Let's create a key pair:</p>
<ul>
<li>Type the command <code>ssh-keygen -t ed25519</code>. (If you get an &quot;unknown key type&quot; error, then you are using an outdated version of OpenSSH and for security reasons you should upgrade immediately.) <em>Note: type <code>ed25519</code> directly, do not replace this with your username. It stands for the &quot;Edwards curve over the prime <code>2^255-19</code>&quot; cryptographic group, if you want to know.</em></li>
<li>When it asks you where to save the file, just press ENTER to accept the default, but make a note of the path - normally it's a folder <code>.ssh</code> in your home directory.</li>
<li>If it asks you &quot;Overwrite (y/n)&quot;, say no (n, then ENTER) as it means you already have a key for something else - either ssh directly or something that uses it, like github. Restart key generation but pick a different file name.</li>
<li>When it asks you for a password, I recommend that you just press ENTER which doesn't set a password (good security, maximum convenience). If you do set a password, it will ask you to type it twice and then you will need the password and the key file to use this key (maximum security, less convenient).</li>
</ul>
<div class="advanced container">
<header><span class="advanced-title"></span></header>
<div class="container-content">
<p>The <code>-t</code> parameter selects the cryptographic algorithm to use, in this case <code>ed25519</code>, which is modern, peer-reviewed, and generally considered one of the most secure public-key algorithms available. However some older ssh versions don't accept ed25519.</p>
<p>If you ever need to use SSH keys to a machine that doesn't like ed25519, then use the key type &quot;rsa&quot; instead. I would personally avoid the alternatives &quot;dsa&quot; and &quot;ecdsa&quot; if at all possible as there is speculation among cryptographers that there may be a flaw in the design.</p>
<p>For example, although seis supports ed25519, the old cs bastion host <code>snowy.cs.bris.ac.uk</code> still uses an older version of SSH, so you would need to generate a rsa key to connect to that.</p>
</div>
</div>
<p>Have a look at the folder where your keys are stored. <code>ls -l ~/.ssh</code> will do this, unless you chose somewhere else to store them when you created them:</p>
<pre><code>-rw-------. 1 vagrant vagrant  411 Oct  7 10:50 id_ed25519
-rw-r--r--. 1 vagrant vagrant   98 Oct  7 10:50 id_ed25519.pub
-rw-r--r--. 1 vagrant vagrant 1597 Oct  7 11:54 known_hosts
</code></pre>
<p>Note the permissions on these files in my example. The private key (first line) has a permissions line at the start of <code>(-)(rw-)(---)(---)</code> where I've added brackets to make clearer what is going on. The first bracket only applies to special file types (e.g. <code>d</code> for directory). Next, the owner permissions which are in this case read and write (the third one would be <code>x</code> if the file were an executable program). The last two brackets are the permissions for the group and for everyone else, and these are all off so no-one except yourself (and root) can read your key file. OpenSSH is picky about this and will refuse to use a private key that other people have access to.</p>
<p>The public key permissions are <code>(-)(rw-)(r--)(r--)</code> which means that the owner can read and write, and the group and everyone else (assuming they have access to the folder) can read the public key, which is fine. It's a public key after all.</p>
<p><code>known_hosts</code> is where SSH stores the public keys of computers you've already connected to: every time you answer yes to an &quot;Are you sure you want to connect?&quot; question when you connect to a new computer for the first time, it stores the result in this file and won't ask you again the next time. The file format is one key per line and you can edit the file yourself if you want to.</p>
<h2><a class="header" href="#set-up-key-access-on-seis" id="set-up-key-access-on-seis">Set up key access on seis</a></h2>
<p>First, we need to upload our public key to the <code>~/.ssh</code> directory on seis. Even before this, we need to make sure the directory exists though:</p>
<ul>
<li>Log in to seis with ssh and your password.</li>
<li>Try <code>ls -al ~/.ssh</code>. If it complains the folder doesn't exist, create it with <code>mkdir ~/.ssh</code>.</li>
<li>Log out of seis again with <code>exit</code>.</li>
</ul>
<p>The command for copying a file is <code>scp</code> for secure copy, which works like <code>cp</code> but allows you to include remote hosts and does the copy over SSH. Run this from your own machine:</p>
<pre><code>scp ~/.ssh/id_ed25519.pub &quot;USERNAME@seis.bris.ac.uk:~/.ssh/&quot;
</code></pre>
<p>Obviously, replace USERNAME with your university username. This will ask for your password again. Note two things here: first, to set up access on seis, we are uploading the public key - not the private key! - and secondly, that we put double quotes around the destination. This is because the <code>~</code> character meaning home directory is handled by our shell, but we don't want our local shell to expand it, instead we want the shell on seis launched by scp to expand it to our home directory on that machine.</p>
<p>The general syntax of scp is <code>scp source destination</code> and source or destination  may be of the form <code>[USERNAME@]HOSTNAME:PATH</code> - if it contains a colon (<code>:</code>), then it refers to a file on a different machine.</p>
<p>Now log in to seis over ssh and type your password one last time. Then run the following:</p>
<pre><code>cd .ssh
cat id_ed25519.pub &gt;&gt; authorized_keys
chmod 600 authorized_keys
</code></pre>
<p>SSH will accept a public key if it is listed in the file <code>authorized_keys</code> in the user's <code>.ssh</code> folder, the format is one line per key. Instead of just copying <code>id_ed25519.pub</code> to <code>authorized_keys</code>, which would overwrite the latter file if it already existed, we use the construction <code>cat SOURCE &gt;&gt; DEST</code> to have our shell append the source file to the destination.</p>
<p>However, if the authorised keys file didn't exist already, then it has now been created with default permissions and SSH won't accept that for security reasons. <code>chmod</code> means change permissions (also known as &quot;mod bits&quot;) and 600 is the bit pattern we want in base 8, because that is how permissions work for historical reasons. Permissions are a bitfield of 9 bits, the first three are read/write/execute for the owner, the next three the same for the group, and then for everyone else. If you <code>ls -l</code> you will see this in a slightly more human-readable format, namely <code>rw-------</code> where a minus means that a bit is turned off.</p>
<p>Now type <code>exit</code> to get back to your own machine, and then <code>ssh USERNAME@seis.bris.ac.uk</code> to log back in to seis. It should log you in without asking for a password, and you have now set up key-based SSH authentication for seis.</p>
<p>Note: if you set a password on your SSH key earlier, then it will ask you for a password, and it will expect the key password not your uni password. You know not to ever reuse your uni password for anything else, right?</p>
<p>If for some reason something doesn't work with ssh, the first thing to try is to add the <code>-v</code> switch enable debugging information (you can even do <code>-vv</code> or <code>-vvv</code> to see even more detail, but we don't need that). If there is a problem with the permissions on your private key file for example, then you will see SSH complain in the debugging information.</p>
<h2><a class="header" href="#setting-up-keys-for-lab-machines" id="setting-up-keys-for-lab-machines">Setting up keys for lab machines</a></h2>
<p>You can now get into seis with a key, but you want to be on a lab machine to get work done.</p>
<p>To connect from your machine to seis, you need a private key on your machine and a public key on seis. To connect from seis to a lab machine, it would seem like you need a public key on the lab machine and a private key on seis. You do not want to upload your private key to seis though for security reasons, so instead we are going to use a SSH feature called <em>agent forwarding</em> which means that if you SSH into one machine, then when you try and SSH further into another machine SSH will reuse the same key. The way to do this is to use the <code>-A</code> command line flag.</p>
<div class="advanced container">
<header><span class="advanced-title"></span></header>
<div class="container-content">
<p>The point of key-based authentication is that your private key never leaves your own machine, so even university administrators never get to see it, which would not be guaranteed if you stored a copy on a university machine.</p>
<p>Logging in to a machine does not send the key to that machine. Instead, the machine sends you a challenge - a long random number - and SSH digitally signs that with the private key on your own machine, and sends the signature back which the remote machine can verify with the public key. Seeing a signature like this does not let the machine create further signatures on your behalf, and it definitely does not reveal the key.</p>
<p>What agent forwarding does is it allows challenges and signatures to be forwarded across multiple connections, but the key never leaves your own machine.</p>
<p>This way, you can create one SSH key and use it for university, github and anything else that you access over SSH, and even if one service is breached then this does not give the attacker access to your accounts on the other services.</p>
</div>
</div>
<ul>
<li>Log in to seis with <code>ssh USERNAME@seis.bris.ac.uk</code>. You should not need a password anymore.</li>
<li>Log in to the lab machines with <code>ssh rd-mvb-linuxlab.bristol.ac.uk</code> and enter your password. Check that the <code>~/.ssh</code> folder exists and create it if it doesn't, as you did before on seis, then <code>exit</code> again to seis.</li>
<li>Copy your public key file from seis to the lab machines with <code>scp ~/.ssh/id_ed25519.pub &quot;rd-mvb-linuxlab.bristol.ac.uk:~/.ssh/&quot;</code>. This will ask for your password again.</li>
<li>Log in to a lab machine with <code>ssh rd-mvb-linuxlab.bristol.ac.uk</code> and enter your password one last time. On the lab machine, install the public key with the following:</li>
</ul>
<pre><code>cd .ssh
cat id_ed25519.pub &gt;&gt; authorized_keys
chmod 600 authorized_keys
</code></pre>
<ul>
<li>Log out of the lab machine and seis again by typing <code>exit</code> twice.</li>
</ul>
<p>The steps above were necessary because your home directory on seis is not the same as on the lab machines. However, your home directory is the same across all lab machines, so you don't need to install the key on each one separately. You might have noticed that when copying or <code>ssh</code>-ing from seis to the lab machines, you don't have to repeat your username: this is because it is the same on all these machines.</p>
<p>From now on, from you own machine, you should be able to get directly into a lab machine with the following command, which should not ask for your password at all:</p>
<pre><code>ssh -A -J USERNAME@seis.bris.ac.uk USERNAME@rd-mvb-linuxlab.bristol.ac.uk
</code></pre>
<p><em>Unfortunately, <code>-J</code> will not work on a windows CMD terminal, although it should work on Windows Subsystem for Linux. Once we have set up a configuration file, there will be a way to work around this problem. Mac and linux users should be fine though, as should anyone running these commands from an Alpine VM on their own machine, whatever their host OS.</em></p>
<h2><a class="header" href="#setting-up-a-configuration-file" id="setting-up-a-configuration-file">Setting up a configuration file</a></h2>
<p>You now have a log in command that works, but you still have to type a lot, and you need to type your username twice. We can improve this by using a configuration file.</p>
<p>SSH reads two configuration files: one for all users at <code>/etc/ssh/ssh_config</code> (<code>/etc</code> is where POSIX programs typically store global settings) and a per-user one at <code>~/.ssh/config</code>. The site <a href="https://www.ssh.com/ssh/config/">https://www.ssh.com/ssh/config/</a> or just <code>man ssh_config | less</code> on a terminal contain the documentation (<code>man</code> means manual page, and <code>less</code> is a program that shows a file on page at a time and lets you scroll and search).</p>
<p>Create a file called simply <code>config</code> in your <code>.ssh</code> directory on your own machine. You can do this for example with <code>touch config</code> (make sure you're in the <code>.ssh</code> directory first, <code>cd ~/.ssh</code> gets you there), and then editing it in your favourite text editor. Add the following lines, replacing USERNAME with your username twice:</p>
<pre><code>Host seis
  HostName seis.bris.ac.uk
  User USERNAME

Host lab
  HostName rd-mvb-linuxlab.bristol.ac.uk
  ProxyJump seis
  User USERNAME
</code></pre>
<p>This now lets you use simply <code>ssh lab</code> to log in to a lab machine via seis (agent forwarding is implied when you use <code>ProxyJump</code>), or <code>ssh seis</code> if you want to access seis directly for example to update your keys there.</p>
<ul>
<li>Try <code>ssh lab</code> from your own machine. This will be your main way to log in to a lab machine from now onwards.</li>
</ul>
<div class="advanced container">
<header><span class="advanced-title"></span></header>
<div class="container-content">
<p>If you want to learn another useful skill as you go along, here is one way to edit files on the command line. Many linux distributions have an editor called <code>nano</code> built in which runs in the terminal, so <code>nano config</code> edits the file called config (creating it if it doesn't exist, when you save for the first time). It is fairly self-explanatory, the command Control+X quits as you can see on the command bar at the bottom of the screen in nano and if you quit with unsaved changes, it will ask you if you want to save.</p>
<p>Nano is installed on seis and on the lab machines, so you can use it to edit a file remotely.</p>
<p>However, nano is not installed by default on alpine linux which we will be using for a lot of this unit - you can install it yourself with <code>sudo apk add nano</code>. </p>
<p>And something for Windows users:</p>
<p>If you are on Windows and are using OpenSSH through a CMD terminal, a bug in OpenSSH prevents the <code>-J</code> option from working. However, you can write your file like this instead:</p>
<pre><code># ~/.ssh/config file for WINDOWS CMD users only

Host seis
  HostName seis.bris.ac.uk
  User USERNAME

Host lab
  HostName rd-mvb-linuxlab.bristol.ac.uk
  ProxyCommand ssh.exe -W %h:%p seis
  User USERNAME
</code></pre>
<p>This should get <code>ssh lab</code> to work for you as well.</p>
</div>
</div>
<h2><a class="header" href="#using-different-keys" id="using-different-keys">Using different keys</a></h2>
<p>You do not need this for the lab, but if you are ever managing different systems and accounts then you might use a different key file for each one. In this case, ssh on the command line lets you do <code>-i FILENAME</code> to select a private key file, and in the configuration file you can select a file for a particular host with the <code>IdentityFile FILENAME</code> line. By default, ssh will search for files in <code>.ssh</code> with names <code>id_CIPHER</code>, as you can see if you launch a connection with the <code>-vv</code> parameter which shows detailed debugging information.</p>
<h1><a class="header" href="#installing-vagrant-and-alpine-linux" id="installing-vagrant-and-alpine-linux">Installing vagrant and alpine linux</a></h1>
<p><a href="https://www.vagrantup.com/">Vagrant</a> is a program to manage virtual machines (VMs). Based on a configuration file called a <code>Vagrantfile</code>, it can download and configure disk images, which it calles boxes, and call other programs to run them. Vagrant does not run the VM by itself, so you will need another program like <a href="https://www.virtualbox.org/">virtualbox</a> for that.</p>
<h2><a class="header" href="#installing-on-your-own-machine" id="installing-on-your-own-machine">Installing on your own machine</a></h2>
<p>To use vagrant on your own machine (recommended), follow these steps:</p>
<ul>
<li>Go to <a href="https://www.vagrantup.com/downloads">https://www.vagrantup.com/downloads</a> and download the version of vagrant for your operating system. Windows, Mac OS and common versions of linux are supported.</li>
<li>Download and install virtualbox from <a href="https://www.virtualbox.org/wiki/Downloads">https://www.virtualbox.org/wiki/Downloads</a>.</li>
<li>Reboot your machine.</li>
</ul>
<p>If you are on linux, you can of course also install the programs from your distribution's repository. Vagrant's developers actually recommend against this because they claim that some distributions package outdated versions, but it is your choice.</p>
<h2><a class="header" href="#configuring-a-box" id="configuring-a-box">Configuring a box</a></h2>
<p>Next, you are going to configure a virtual machine using <a href="https://www.alpinelinux.org/">alpine linux</a>, a minimal linux distribution that we will be using in this unit. </p>
<ul>
<li>Create an empty folder somewhere.</li>
<li>In that folder, create a file called Vagrantfile (capitalised, and with no extension) and add the following lines to it - or just download the file from <a href="act1/../resources/Vagrantfile">here</a>:</li>
</ul>
<pre><code class="language-ruby">Vagrant.configure(&quot;2&quot;) do |config|
  config.vm.box = &quot;generic/alpine310&quot;
  config.vm.synced_folder &quot;.&quot;, &quot;/vagrant&quot;

  config.vm.provision &quot;shell&quot;, inline: &lt;&lt;-SHELL
    apk add libc6-compat util-linux
  SHELL
  config.vm.provision :shell, run: 'always', inline: &lt;&lt;-SHELL
	umount /vagrant
	/sbin/mount.vboxsf -o uid=1000 -o gid=1000 vagrant /vagrant
	chmod go+rx /vagrant
  SHELL
end
</code></pre>
<p>This configuration file is actually a script in the ruby programming language, but you don't need to learn that to use vagrant. Let's look at what it does.</p>
<ul>
<li><code>config.vm.box</code> selects the virtual machine image, or box in vagrant-speak, to use. You can see a list of available ones at https://app.vagrantup.com/boxes/search.</li>
<li><code>config.vm.synced_folder</code> sets up a shared folder between the guest (virtual machine) and host (your machine).</li>
<li>The first <code>config.vm.provision</code> runs a provisioning command when the box is first downloaded and installed. These commands run as root on the virtual machine, and in this case we are using the <code>apk</code> package manager (we will talk about this later on) to install two packages <code>libc6-compat</code> and <code>util-linux</code>.</li>
<li>The second <code>config.vm.provision</code> is tagged with <code>run: 'always'</code> so it runs every time the virtual machine starts. It turns out there is a bug in how shared folders work that means alpine linux and virtualbox don't get along; the three lines of commands after that get the shared folder working correctly again. We will learn what they do later on.</li>
<li>The <code>&lt;&lt;-SHELL</code> construction is called a &quot;here document&quot;, and is a way in some programming languages of writing multi-line strings. It tells ruby to treat everything until the closing keyword SHELL (which is arbitrary) as a string, which can contain several lines.</li>
</ul>
<div class="advanced container">
<header><span class="advanced-title"></span></header>
<div class="container-content">
<p>Alpine linux uses the musl libc distribution, which is smaller than and has a few distinct differences from the normal GNU libc. To avoid these incompatibilities causing you hard-to-find problems when you are compiling C programs, we are installing <code>libc6-compat</code> that makes alpine compatible with the standard libc. <code>util-linux</code> contains a few standard linux command line tools that are not installed by default on alpine - it really is that minimal.</p>
</div>
</div>
<h2><a class="header" href="#running-vagrant" id="running-vagrant">Running vagrant</a></h2>
<ul>
<li>Open a terminal in the folder containing the Vagrantfile. If you are on windows, both the windows CMD and the windows subsystem for linux terminal will work equally well for this purpose.</li>
<li>Run the command <code>vagrant up</code>. This starts the virtual machine configured in the current folder, and if it has not been downloaded and provisioned yet (as is the case when you run <code>up</code> for the first time) then it does this for you as well.</li>
<li>When vagrant tells you the machine is running, run <code>vagrant ssh</code> to log in to your virtual machine. If it asks you for a password, use <code>vagrant</code>.</li>
<li>You should now see the virtual machine prompt <code>alpine310:~$</code>. Try the command <code>ls /</code> and check that there is a folder called vagrant in the top-level folder, along with system ones with names like <code>usr</code> and <code>bin</code>.</li>
</ul>
<p>There are two kinds of errors you might get during <code>vagrant up</code>:</p>
<ul>
<li>If vagrant complains that it can't find a provider, then you have probably not installed virtualbox, or not rebooted since installing it.</li>
<li>If you get some odd crash or error message about hypervisors, see the page <a href="https://www.vagrantup.com/docs/installation">https://www.vagrantup.com/docs/installation</a> for instructions, section <em>Running Multiple Hypervisors</em>. Basically, you cannot run vagrant when another program is already using your processor's virtualisation subsystem, and the page gives instructions how to turn off the other one.</li>
</ul>
<h2><a class="header" href="#shutting-down-cleanly" id="shutting-down-cleanly">Shutting down cleanly</a></h2>
<p>To exit the virtual machine, type <code>exit</code> which will get you back to the shell on the host machine. On the host, <code>vagrant halt</code> cleanly shuts down the virtual machine.</p>
<p>Promise yourself that you will always do this before turning off your computer, if you have been using vagrant!</p>
<h2><a class="header" href="#running-on-a-lab-machine" id="running-on-a-lab-machine">Running on a lab machine</a></h2>
<p>Vagrant is already installed on the lab machines in MVB 2.11, so you can remotely log in and launch a box from there. This will get you exactly the same alpine environment as if you run on your own machine, and everyone should try this out too. If for some reason you cannot run vagrant on your machine, then as long as you have an internet connection you should still be able to run it on the lab machines.</p>
<p>First, we connect to a lab machine: open a terminal and run the command <code>ssh lab</code> that you configured in the previous section on SSH.</p>
<p>On the lab machine, we need to create a folder and load a Vagrantfile as above, but let's download the Vagrantfile from the unit webpage instead of typing it out. Run the following shell commands:</p>
<pre><code class="language-sh">mkdir softwaretools
cd softwaretools
wget https://raw.githubusercontent.com/cs-uob/COMS10012/master/resources/week1/Vagrantfile
</code></pre>
<p>You can call the top folder (softwaretools) anything you like and put it anywhere you want. You can now run <code>vagrant up</code> followed by <code>vagrant ssh</code> from inside that folder.</p>
<div class="advanced container">
<header><span class="advanced-title"></span></header>
<div class="container-content">
<p>When you <code>vagrant up</code>, vagrant internally connects port 22 on the guest (which <code>sshd</code> on the guest is listening to) to port 2222 on the host. When you provision a vagrant machine, this creates a key pair on the host and loads the public key into the guest. The private key is actually in the file <code>.vagrant/machines/default/virtualbox/private_key</code> on the host, and the public key in <code>/home/vagrant/.ssh/authorized_keys</code> on the guest. So what <code>vagrant ssh</code> does is launch <code>ssh -i KEYFILE vagrant@localhost -p 2222</code>.</p>
</div>
</div>
<h2><a class="header" href="#warning-about-lab-machines---read-carefully" id="warning-about-lab-machines---read-carefully">Warning about lab machines - read carefully!</a></h2>
<p>Your files in your home directory on a lab machine are stored in a network folder, so that you see the same files whichever lab machine you log in to; they are also automatically backed up.</p>
<p>If lots of students created lots of VMs in their home folders, this would take up lots of space, and it would be slow: running an operating system over a network share causes both bandwidth and latency problems.</p>
<p>Instead, IT has configured vagrant on the lab machines to store VMs in the <code>/tmp</code> folder which is local to each machine. This means that:</p>
<ul>
<li>If you log in to a different lab machine, your VMs will be gone.</li>
<li>If you log in to the same lab machine but it has restarted since you last logged in, your VMs will be gone.</li>
<li>Your VMs, and with them any files you store in the VM itself, are not backed up.</li>
</ul>
<p>This is not as much a problem as it seems because this is how virtual machines are meant to work: if one is not available, vagrant downloads and provisions it. For this reason, for any software you want installed on your VMs in the lab machines, you should write the install command into the provisioning script in the Vagrantfile so it will be re-installed the next time Vagrant has to set up the VM. We will learn how to do this soon.</p>
<p>However, this still leaves files that you create on the VM itself, such as the ones you will create for the exercises in this unit. The basic warning is that <em>any files in your home directory will be lost when the VM is rebuilt</em>. That is why we have set up a shared folder which you can access as <code>/vagrant</code> on the VM, which maps to the folder containing your Vagrantfile on the host machine. Because this is stored under your home folder on the lab machine, it lives on the network file store and so it is backed up and available from all lab machines.</p>
<p>So whenever you log in to a VM on a lab machine to do some work, you should <code>cd /vagrant</code> and use that instead of your home folder for any files that you don't want to lose. If you are running vagrant on your own computer, then nothing will be deleted except if you give vagrant a command to rebuild the VM yourself.</p>
<h1><a class="header" href="#alpine-linux-system-administration" id="alpine-linux-system-administration">Alpine linux system administration</a></h1>
<p>Start your alpine box if necessary by going to the folder with the <code>Vagrantfile</code> in your terminal, and typing <code>vagrant up</code>. Log in to your alpine linux box with <code>vagrant ssh</code>. We are going to get to know linux in general and alpine in particular a bit.</p>
<h2><a class="header" href="#the-file-system" id="the-file-system">The file system</a></h2>
<p>Linux (and other POSIX-like operating systems) work with a single file hierarchy with a root folder <code>/</code>, although there may be different file systems mounted at different places under that. How files are organised in here are documented in the <a href="https://refspecs.linuxfoundation.org/FHS_3.0/fhs-3.0.html">Filesystem Hierarchy Standard (FHS)</a>. Have a look with the command <code>ls /</code>:</p>
<p><code>/bin</code> stands for binaries, that is programs that you can run. Have a look with <code>ls /bin</code>: there will be a lot of commands in here, including ls itself. Indeed you can find out where a program is with <code>which</code>, so <code>which ls</code> will show you <code>/bin/ls</code> for example.</p>
<p>If you have colours turned on (which is the default) you will see that a couple of files like <code>bash</code> are green, but the rest are blue - this indicates the file type, green is an executable program, blue is a link to another file. Have a look with <code>ls -l /bin</code>: the very first character of each line indicates the file type, the main ones being <code>-</code> for normal file, <code>d</code> for directory and <code>l</code> for a so-called <em>soft link</em>.</p>
<p>Note that, as you can see on the last entry of each line, most files here are links to <code>/bin/busybox</code>! Busybox is, in its own words:</p>
<blockquote>
<p>BusyBox is a multi-call binary that combines many common Unix
utilities into a single executable.  Most people will create a
link to busybox for each function they wish to use and BusyBox
will act like whatever it was invoked as.
(from <code>busybox --help</code>)</p>
</blockquote>
<p>Busybox is a distribution of the many common POSIX commands (you can see which ones with <code>busybox --help</code>) packed into a single program. This means that you can run for example <code>busybox ls</code> to run the ls command. However, when you call <code>ls</code> directly, your shell runs the <code>/bin/ls</code> command, which is just a link to busybox. </p>
<div class="advanced container">
<header><span class="advanced-title"></span></header>
<div class="container-content">
<p>How does busybox know which command you want?</p>
<p>Remember that in C, each program's main function can take an argument vector <code>char **argv</code> and that <code>argv[0]</code> is the name of the file that was used to call the program - this is what busybox looks at when you call <code>ls</code> or any of the other linked programs in <code>/bin</code>.</p>
</div>
</div>
<p>Busybox is used in alpine linux because alpine is a minimal linux distribution and busybox is a minimal implementation of lots of common commands. As a result, the alpine/busybox version of say ls might not have as many options as the ls on the lab machines.</p>
<p>Back to <code>ls /</code> and the folders in the root folder. <code>/etc</code> stores system-wide configuration files and typically only root (the administrator account) can change things in here. For example, system-wide ssh configuration lives in <code>/etc/ssh</code>.</p>
<p><code>/lib</code> contains dynamic libraries - windows calls these <code>.dll</code> files, POSIX uses <code>.so</code>. For example, <code>/lib/libc.so.6</code> is the C library, which allows C programs to use functions like <code>printf</code>. You can see with <code>ls -l /lib</code> that the C library is actually a link to <code>/lib/libc.musl-x86_64.so.1</code>: <a href="https://musl.libc.org/">musl</a> is a minimal implementation of the C library, which is the version that alpine linux chose to use by default. From their website:</p>
<blockquote>
<p>musl is an implementation of the C standard library built on top of the Linux system call API, including interfaces defined in the base language standard, POSIX, and widely agreed-upon extensions. musl is lightweight, fast, simple, free, and strives to be correct in the sense of standards-conformance and safety.</p>
</blockquote>
<p><code>/home</code> is the folder containing users' home directories, for example the default user vagrant gets <code>/home/vagrant</code>. The exception is root, the administrator account, who gets <code>/root</code>.</p>
<p><code>/sbin</code> (system binaries) is another collection of programs, typically ones that only system administrators will use. For example, <code>fdisk</code> creates or deletes partitions on a disk and lots of programs with <code>fs</code> in their name deal with managing file systems. <code>/sbin/halt</code>, run as root (or another user that you have allowed to do this), shuts down the system; there is also <code>/sbin/reboot</code>.</p>
<p><code>/usr</code> is a historical accident and a bit of a mess. A short history is on <a href="https://askubuntu.com/questions/130186/what-is-the-rationale-for-the-usr-directory">this stackexchange question</a> but essentially, in the earliest days,</p>
<ul>
<li><code>/bin</code> was only for binaries needed to start the system - or at least the most important binaries that needed to live on the faster of several disk drives, like your shell.</li>
<li><code>/usr/bin</code> was where most binaries lived which were available globally, for example across all machines in an organisation.</li>
<li><code>/usr/local/bin</code> was for binaries installed by a local administrator, for example for a department within an organisation.</li>
</ul>
<p>In any case, <code>/usr</code> and its subfolders are for normally read-only data, such as programs and configuration files but not temporary data or log files. It contains subfolders like <code>/usr/bin</code> or <code>/usr/lib</code> that duplicate folders in the root directory.</p>
<p>Ubuntu's way of cleaning this mess up is to make its <code>/bin</code> just a link to <code>/usr/bin</code> and putting everything in there. On alpine linux, there is still a distinction between the two, but most binaries in both folders are links to <code>/bin/busybox</code> anyway. For example, if you do <code>which ls</code> you find <code>/bin/ls</code>, but <code>which which</code> shows <code>/usr/bin/which</code>, but both of these are in fact just links to <code>/bin/busybox</code>.</p>
<p><code>/tmp</code> is a temporary filesystem that may be stored in RAM instead of on disk (but swapped out if necessary), and that does not have to survive rebooting the machine.</p>
<p><code>/var</code> holds files that vary over time, such as logs or caches.</p>
<p><code>/dev</code>, <code>/sys</code> and <code>/proc</code> are virtual file systems. One of the UNIX design principles is that almost every interaction with the operating system should look to a program like reading and writing a file, or in short <em>everything is a file</em>. For example, <code>/dev</code> offers an interface to devices such as hard disks (<code>/dev/sda</code> is the first SCSI disk in the system, and <code>/dev/sda1</code> the first partition on that), memory (<code>/dev/mem</code>), and a number of pseudoterminals or ttys that we will talk about later. <code>/proc</code> provides access to running processes; <code>/sys</code> provides access to system functions. For example, on some laptop systems, writing to <code>/sys/class/backlight/acpi_video0/brightness</code> changes the screen brightness.</p>
<p>The <code>/vagrant</code> folder is not part of the FHS, but is a convention for a shared folder with the host on vagrant virtual machines.</p>
<h2><a class="header" href="#package-managers" id="package-managers">Package managers</a></h2>
<p>Linux has had package managers and repositories since the days when it was distributed on floppy disks. A repository is a collection of software that you can install, and can be hosted anywhere - floppy disk, CD-ROM, DVD or nowadays on the internet. A package manager is software that installs packages from a repository - so far, this sounds just like an <em>app store</em> but a package manager can do more. For one thing, you can ask to install different versions of a particular package if you need to. But the main point of a package manager is that packages can have dependencies on other packages, and when you install one then it installs the dependencies automatically.</p>
<p>Nano is a basic text editor that works in the console, and is installed in most linux distributions including the ones on seis and the lab machines, so you can use it to edit files remotely. However, in alpine linux it is not installed by default: type <code>nano</code> and you get <code>nano: command not found</code>. You can install it with the command</p>
<pre><code>sudo apk add nano
</code></pre>
<ul>
<li><code>sudo</code> (superuser do) allows you to run a command as root, also known as the administrator or superuser. Depending on how your system is configured, this might be not allowed at all (you can't do it on the lab machines), or require a password, but on the alpine/vagrant distribution you are allowed to do this. It is good practice to use sudo for system adminstration instead of logging in as root directly, but if you ever really need a root shell then <code>sudo bash</code> gets you one - with <code>#</code> instead of <code>$</code> as prompt to warn you that you are working as root.</li>
<li><code>apk</code> is the alpine linux package manager.</li>
<li><code>add PACKAGE</code> adds a package, which means download and install it and all its dependencies (nano is so small that it has none).</li>
</ul>
<p>You can now do <code>nano FILENAME</code> to edit a file. The keyboard shortcuts are at the bottom of the screen, the main one you need is Control+X to exit (it will ask if you want to save, if you have unsaved changes).</p>
<p>Next, install git with <code>sudo apk add git</code>. Git requires two dependencies (apart from the ones already installed on the base system), as you can see in the output:</p>
<pre><code>(1/3) Installing expat (2.2.8-r0)
(2/3) Installing pcre2 (10.33-r0)
(3/3) Installing git (2.22.4-r0)
</code></pre>
<p><code>expat</code> is an XML parser (for configuration files) and <code>pcre2</code> implements perl-compatible regular expressions for searching for text.</p>
<p>We can use apk to explore this further, try the following:</p>
<ul>
<li><code>apk info git</code> shows information about the git package, including a short description and the website.</li>
<li><code>apk info -a git</code> shows more information, including the dependencies (section &quot;depends on&quot;, there are 5 listed but two are already part of the base system, <code>libc.musl</code> is the C library and <code>libz</code> is a compression library similar to &quot;zip&quot;) and a list of all files installed by the package.</li>
</ul>
<p>Note how git is built out of a number of subcommands in <code>/usr/libexec</code>. For example, when you do <code>git branch</code>, that ends up calling <code>/usr/libexec/git-core/git-branch</code>.</p>
<p>The commands above did not require <code>sudo</code> as they do not change any files on the system.</p>
<h2><a class="header" href="#update-and-upgrade" id="update-and-upgrade">Update and upgrade</a></h2>
<p>The repositories that you are using are recorded in <code>/etc/apk/repositories</code>, have a look at this file with <code>cat</code> or <code>nano</code> to see where they are, then look up the sites in your browser. There are folders for different processor architectures (the one in use is stored in <code>/etc/apk/arch</code>) and these contain all the packages as well as a file <code>APKINDEX.tar.gz</code> that contains a list of all packages and versions.</p>
<p>Two commands a system adminstrator should run regularly for security reasons:</p>
<ul>
<li><code>sudo apk update</code> fetches the new package list from the repository. This way, apk can tell you if any packages have been updated to new versions since you last checked.</li>
<li><code>sudo apk upgrade</code> upgrades every package that you already have installed to the latest version in your local package list (downloaded when you do an <code>apk update</code>).</li>
</ul>
<h2><a class="header" href="#lab-machines" id="lab-machines">Lab machines</a></h2>
<p>If you are running a virtual machine on the lab machines, then your virtual machine might not be around after the lab machine reboots or you log out and in again and end up on a different machine - as the notice when you log in tells you, the virtual machines are stored under <code>/tmp</code>.</p>
<p>It would be annoying to have to reinstall your favourite packages every time you log in to a different machine, so you should put them in your Vagrantfile and then <code>vagrant up</code> will do this for you automatically. The Vagrantfile already contains a line <code>apk add libc6-compat util-linux</code> which installs two packages by default - you can put as many as you like on this line separated by spaces. There is no <code>sudo</code> here because when vagrant is installing the system, it is running as root automatically.</p>
<ul>
<li>Add <code>nano</code> and <code>git</code> to this line so next time you rebuild the vagrant machine, they are added automatically.</li>
<li>Log out of your vagrant machine and do a <code>vagrant destroy</code> which removes the virtual machine. Then reload with <code>vagrant up</code> which will download and provision the box again.</li>
<li>Log in with <code>vagrant ssh</code> and check that git and nano are installed.</li>
</ul>
<p>For the next exercise, please also install the <code>gcc</code> package that gets you a C compiler, as well as <code>musl-dev</code> which contains header files like <code>stdio.h</code>. These, in case you wondered, live in <code>/usr/include</code>.</p>
<h1><a class="header" href="#shell-expansion" id="shell-expansion">Shell expansion</a></h1>
<p>This exercise is about studying shell expansion. You should run it on your alpine linux VM in vagrant, and you should have installed the <code>gcc</code> compiler.</p>
<p>Create a C program <code>arguments.c</code> with the following contents. You can use <code>nano arguments.c</code> for this, for example.</p>
<pre><code class="language-C">#include &lt;stdio.h&gt;

int main(int argc, char** argv) {
  for(int i=0; i &lt; argc; i++) {
    printf(&quot;Argument #%i: [%s]\n&quot;, i, argv[i]);
  }
  return 0;
}
</code></pre>
<p>Compile this with <code>gcc -Wall arguments.c -o arguments</code>. </p>
<h2><a class="header" href="#whitespace" id="whitespace">Whitespace</a></h2>
<p>The program prints all its arguments, one per line. The program gets its arguments from the program that started it - in this case the shell.
Try running the program with the following commands:</p>
<pre><code>./arguments
./arguments hello
./arguments one two three
</code></pre>
<p>Now that you are familiar with what the program does, try the following:</p>
<pre><code>./arguments one       two
./arguments &quot;one two&quot;
./arguments &quot;one      two&quot;
</code></pre>
<p>How, based on these examples, does the shell handle whitespace in the line you type?</p>
<h2><a class="header" href="#pattern-matching" id="pattern-matching">Pattern matching</a></h2>
<p>Try the following:</p>
<ul>
<li><code>./arguments *</code> in the folder that contains the arguments program, and its source code arguments.c.</li>
<li>Make an empty subfolder with <code>mkdir empty</code>, switch to it with <code>cd empty</code> and then run <code>../arguments *</code>. Since you are now in the subfolder, we need two dots at the start to say &quot;run the program arguments in the folder <em>above</em>&quot;. What happens?</li>
<li>Go back to the folder with the program by running <code>cd ..</code> and then do <code>ls</code> to check you're back in the right folder. In this folder, find three different ways to get the program to produce the following output:</li>
</ul>
<pre><code>Argument #0: [./arguments]
Argument #1: [*] 
</code></pre>
<h2><a class="header" href="#files-with-spaces-in-their-names" id="files-with-spaces-in-their-names">Files with spaces in their names</a></h2>
<p>The command <code>touch FILENAME</code> creates a file. Create a file with a space in its name by typing <code>touch &quot;silly named file&quot;</code>. What would happen if you left the quuotes off (you can try it, then do <code>ls</code>)?</p>
<p>Start typing <code>ls sill</code> and then press TAB to autocomplete. Assuming you have no other files whose name starts with <em>sill</em>, what happens? Use this method to get the arguments program to print the following:</p>
<pre><code>Argument #0: [./arguments]
Argument #1: [Hello world!] 
</code></pre>
<p>The command <code>rm</code> (remove) deletes files again. Use it to remove your file with spaces in its name, using one of several methods to get the shell to pass the spaces through to <code>rm</code>.</p>
<h2><a class="header" href="#shell-variables" id="shell-variables">Shell variables</a></h2>
<p>In the shell, <code>VARIABLE=VALUE</code> sets a variable to a value and <code>$VARIABLE</code> retrieves its value. For example, to save typing a filename twice:</p>
<pre><code>p=arguments
gcc -Wall $p.c -o $p
</code></pre>
<p>which expands to <code>gcc -Wall arguments.c -o arguments</code>. If you want to use a variable inside a word, you can use curly braces: <code>${a}b</code> means the value of the variable <code>a</code> followed by the letter b, whereas <code>$ab</code> would mean the value of the variable <code>ab</code>.</p>
<p>It is good practice to double-quote variables used like this, because if you tried for example to compile a program called <code>silly name.c</code> with a space in its name, then</p>
<pre><code>program=&quot;silly name&quot;
gcc -Wall $program.c -o $program
</code></pre>
<p>would expand to</p>
<pre><code>gcc -Wall silly name.c -o silly name
</code></pre>
<p>and this would confuse your compiler because you are telling it to compile three source files called <code>silly</code>, <code>name.c</code> and <code>name</code> to a program called <code>silly</code>. Correct would be:</p>
<pre><code>program=&quot;silly name&quot;
gcc -Wall &quot;$program.c&quot; -o &quot;$program&quot;
</code></pre>
<p>which expands to</p>
<pre><code>gcc -Wall &quot;silly name.c&quot; -o &quot;silly name&quot;
</code></pre>
<p>which does what you want - if you indeed want a program with a space in its name!</p>
<p>There is no harm in double-quoting a shell variable every time you want to use it, and this is good practice as it still works if the variable is set to a value that contains spaces.</p>
<p>Note that we also had to quote setting the variable name in the first place, because</p>
<pre><code>program=silly name
</code></pre>
<p>would translate as: set the variable <code>program</code> to the value <code>silly</code>, then execute the program <code>name</code>. Variable assignments only apply to the first argument following them, although you can assign more than one variable.</p>
<p>Note that this does not work as expected either:</p>
<pre><code>file=arguments gcc -Wall &quot;$file.c&quot; -o &quot;$file&quot;
</code></pre>
<p>The problem here is that the shell first reads the line and substitutes in the value of <code>$file</code> (unset variables expand to the empty string by default) before starting to execute the command, so you are reading the variable's value before writing it. Leaving off the quotes doesn't help: you need to set the variable on a separate line.</p>
<h1><a class="header" href="#git-part-1" id="git-part-1">Git, part 1</a></h1>
<p>For this exercise, I am assuming that you are working on alpine linux and have nano, git and gcc with musl-dev installed as in the last exercise.</p>
<h2><a class="header" href="#configuring-your-identity" id="configuring-your-identity">Configuring your identity</a></h2>
<p>Run the following two lines to set up git correctly. You only need to do this once when you install git, but not every time you create a new repository.</p>
<pre><code>git config --global user.name &quot;YOURNAME&quot;
git config --global user.email &quot;YOUREMAIL&quot;
</code></pre>
<p>where you obviously replace your name and email with something of your choice; I've put them in double quotes because this lets you include a space between your first and last names and the @ character in your email address.</p>
<p>This does not create a user account - git just uses your name and email to record the author in any commits you make, so you can put anything you like here (git will happily accept <code>-</code> as your email address, and it does not send you email). Of course, once you are working in a team with other students, you will probably want to use your real name so they know who has made which commits.</p>
<p>If you are running a VM on a lab machine, then you would need to reconfigure git every time vagrant rebuilds the VM, for example when you log in to a different lab machine. You can put these commands in your Vagrantfile, like anything else that you want to run when vagrant (re)builds your box, but they need to be run as the vagrant user and not the root user. So add the following block to your vagrantfile just before the <code>end</code> line, editing your name and email address obviously; the key point being the <code>privileged: false</code> entry which runs the commands as the <code>vagrant</code> user:</p>
<pre><code>config.vm.provision :shell, privileged: false, inline: &lt;&lt;-SHELL
    git config --global user.name &quot;YOURNAME&quot;
    git config --global user.email &quot;YOUREMAIL&quot;
SHELL
</code></pre>
<p>Of course this will only work if git is installed, but you've added git to the <code>apk add</code> line in the previous provision block already so it will be installed.</p>
<h2><a class="header" href="#a-sample-project-and-repository" id="a-sample-project-and-repository">A sample project and repository</a></h2>
<p>Let's say you want to start developing a C program. Let's make a folder:</p>
<pre><code>mkdir project1
cd project1
git init
</code></pre>
<p>The last command created an empty git repository in a subfolder called <code>.git</code>. We can check with <code>git status</code> to see whether there are any changes, and git reports <code>nothing to commit</code>.</p>
<p>Create a file, for example with <code>nano main.c</code> and add some sample content like this (you should be able to copy-paste into your terminal):</p>
<pre><code class="language-C">// file: main.c
#include &lt;stdio.h&gt;

int main() {
    puts(&quot;Hi&quot;);
    return 0;
}
</code></pre>
<div class="advanced container">
<header><span class="advanced-title"></span></header>
<div class="container-content">
<p>If you install the <code>nano-syntax</code> package, you get syntax highlighting in nano, but you need to configure this first. The syntax files themselves live in <code>/usr/share/nano</code>, for example <code>c.nanorc</code> for the C language, but you have to include the ones you want in a file <code>~/.nanorc</code>. For example, if this file contains the line <code>include /usr/share/nano/c.nanorc</code> then nano will do syntax highlighting on C files. You can turn this on and off with Alt+Y.</p>
<p>On another note - if you just want to print a simple string in C, then please use puts not printf. Printf with one argument is silly and, depending on how you write it, also insecure.</p>
</div>
</div>
<p>Do a <code>git status</code> and you will see <code>main.c</code> in red under <em>untracked files</em> - this is a new file that git does not know about yet. Do <code>git add main.c</code> followed by another <code>git status</code> and the file is now green under <em>files to be committed</em>.</p>
<p>Commit the file with <code>git commit -m &quot;first file&quot;</code> or something like that - you need double quotes if you want spaces in your commit message. Try <code>git status</code> again and you should see <em>nothing to commit, working tree clean</em> which means git is up to date with your files. Try <code>git log</code> and you will see that there is now one commit in the log.</p>
<div class="advanced container">
<header><span class="advanced-title"></span></header>
<div class="container-content">
<p>Every git commit must have a commit message. You can either add one with the <code>-m</code> flag, or leave that off and git will drop you into the system default editor to write one. That is normally vi, which has a unique set of keyboard commands (the command to quit is <code>:q</code> followed by ENTER). You can run the shell command <code>export EDITOR=nano</code> to change your default editor, then a raw <code>git commit</code> will launch nano. If you want to keep this setting when you relaunch your shell next time you log in, then the export line has to go in a file called <code>.profile</code> in your home directory, which is a file that the bash shell processes when it starts up.</p>
<p>To keep a profile file around when vagrant rebuilds your VM if you're on a lab machine, I would put the file in <code>/vagrant/.profile</code> as that is backed up (it ends up in the folder on the host machine with the Vagrantfile) and then put the following command in your non-privileged provisioning block from the last advanced note: <code>ln -s /vagrant/.profile /home/vagrant/.profile</code>. This creates a soft link like you have already seen in <code>/bin</code> earlier.</p>
</div>
</div>
<h2><a class="header" href="#ignoring-files" id="ignoring-files">Ignoring files</a></h2>
<p>Compile your code with <code>gcc main.c -o program</code>, and check with <code>./program</code> that it runs and prints <em>Hi</em>. (If you get an error that <code>stdio.h</code> doesn't exist, then you have installed gcc but not <code>musl-dev</code> which is the package that contains the header files.)</p>
<p>If you look at <code>git status</code> now, the program file shows as untracked, but we do not want to commit it: the repository works best when you store only your source code, and anyone who needs to can check out a copy and build from there. Among other things this means that people on different platforms e.g. linux and mac, intel and ARM and so on can each compile the version that works for them.</p>
<p>So we want to tell git to ignore the program and changes in it, which we do by creating a file called <code>.gitignore</code> and adding an expression on each line to say which file(s) or folders to ignore - you can use <code>*.o</code> to select all object code files, for example.</p>
<ul>
<li>Create a file <code>.gitignore</code> and add the single line <code>program</code> to it.</li>
<li>Do another <code>git status</code> and notice that while the program is now ignored, the ignore file is marked as new. This file does belong in the repository, so add it and commit it.</li>
<li>Check that <code>git status</code> reports <em>clean</em> again, and that <code>git log</code> contains two commits.</li>
</ul>
<h2><a class="header" href="#commit-and-checkout" id="commit-and-checkout">Commit and checkout</a></h2>
<p>As you develop, you should regularly code, commit, repeat. To practice this, change <em>Hi</em> to <em>Hello</em> in the program, rebuild and run the program, then add and commit the source file again - check with <code>git status</code> at the end that you get <em>clean</em> again.</p>
<p>The command <code>git add .</code> adds all new and changed files and folders in the current folder in one go, and is typically the quickest way to add things when you want to commit all your changes since the last commit.</p>
<p>Sometimes you want to go back and look at another commit, or undo a commit that broke something - this is when you want a checkout.</p>
<ul>
<li>Use <code>git log</code> to show the history of your commits. (When you have more than one screen, <code>git log |less</code> lets you scroll.)</li>
<li>Note the first 6 or so characters of the commit hash of the commit where you added the ignore file, but before changing <em>Hi</em> to <em>Hello</em>. You need at least 6 characters, but only as many so that it's not ambiguous to git which commit you mean.</li>
<li>Run <code>git checkout HASH</code> where HASH is the 6 or however many you need characters of the commit in question. Git will print a warning about the HEAD pointer.</li>
<li>Check the source file, and notice that it is now back on <em>Hi</em>.</li>
<li>Use <code>git checkout master</code> to return to the latest version of your files, and git will set up the HEAD pointer again ready to accept new commits.</li>
</ul>
<div class="advanced container">
<header><span class="advanced-title"></span></header>
<div class="container-content">
<p>If you actually want to undo a commit, then you have two options:</p>
<ul>
<li><code>git revert HASH</code> adds a new commit that returns the files to the state they were before the commit with the given hash. This is safe to use during team development, as it's just adding a new commit. If you have commits A, B and do <code>git revert B</code> then you get a new commit C so anyone else using the repository sees a sequence of commits A, B, C; but the state of the files in C is the same as in A.</li>
<li><code>git reset HASH</code> undoes commits by moving the HEAD pointer back to the commit with the given hash, but leaves the working copy alone (you can use the <code>--hard</code> option to change the files as well). This will break things if you have shared your newer commits with other developers, but it's safe to use to undo changes that you haven't pushed yet (we'll learn about this next time). The effect is as if the commits which you've reset had never happened.</li>
</ul>
<p>Note: if you want to revert a commit because you accidentally commited a file with secret information, and you've already pushed the commit, then you also have to look up online how to &quot;force push&quot; your changes to erase all traces of the file on github (or other online providers). If the secret file contained any passwords, even if you reverted the commit immediately, then you should consider the passwords compromised and change them at once.</p>
</div>
</div>
<h1><a class="header" href="#activity-2" id="activity-2">Activity 2</a></h1>
<h2><a class="header" href="#videos-1" id="videos-1">Videos</a></h2>
<table><thead><tr><th>Video</th><th align="right">Length</th><th>Mediasite</th><th>Slides</th></tr></thead><tbody>
<tr><td><a href="https://ams-hsta-ims-ond.mediasite.com/MediasiteDeliver/vol01/bristoluniversity/MP4Video/09947229-01c2-42f4-913a-47e0f408b65a.mp4/QualityLevels(698000)">Permissions</a></td><td align="right">49 minutes</td><td><a href="https://mediasite.bris.ac.uk/Mediasite/Play/59ae0300ae054920a37768c1c4b437ee1d">mediasite</a></td><td><a href="act2//COMS10012/slides/Permissions.pdf">slides</a></td></tr>
<tr><td><a href="https://ams-hsta-ims-ond.mediasite.com/MediasiteDeliver/vol01/bristoluniversity/MP4Video/65e03330-3058-4f80-a8a9-91dab2b975ac.mp4/QualityLevels(698000)">Git, part 2</a></td><td align="right">27 minutes</td><td><a href="https://mediasite.bris.ac.uk/Mediasite/Play/381294eb61ff4e4cb62368ebd743f7a81d">mediasite</a></td><td><a href="act2//COMS10012/slides/Git%202.pdf">slides</a></td></tr>
<tr><td><a href="https://ams-hsta-ims-ond.mediasite.com/MediasiteDeliver/vol01/bristoluniversity/MP4Video/33932285-e7fb-4a31-8af9-7d0de41299b0.mp4/QualityLevels(698000)">Pipes</a></td><td align="right">37 minutes</td><td><a href="https://mediasite.bris.ac.uk/Mediasite/Play/de6ff5b226534e13824d766fee59ec0a1d">mediasite</a></td><td><a href="act2//COMS10012/slides/pipes.pdf">slides</a></td></tr>
</tbody></table>
<h2><a class="header" href="#exercises-1" id="exercises-1">Exercises</a></h2>
<ul>
<li><a href="act2/./permissions.html">File permissions</a></li>
<li><a href="act2/./git2.html">Git, part 2</a></li>
<li><a href="act2/./pipes.html">Pipes</a></li>
</ul>
<h1><a class="header" href="#file-permissions" id="file-permissions">File permissions</a></h1>
<p>Log in to your vagrant VM for the following exercises.</p>
<h2><a class="header" href="#show-the-current-user" id="show-the-current-user">Show the current user</a></h2>
<p>First, use the command <code>whoami</code> to see the current user name: it should be <code>vagrant</code>.</p>
<p>For this exercise it will be useful to display the user in the prompt, so do <code>sudo nano /etc/profile</code>. This file is a configuration file that is read by the shell when it starts up. Notice the lines:</p>
<pre><code>export CHARSET=UTF-8
export LANG=C.UTF-8
export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
export PAGER=less
export PS1='\h:\w\$ '
umask 022
</code></pre>
<p>The <code>export</code> ones set environment variables, for example the default <code>PATH</code> where the shell looks for programs. The <code>PAGER</code> is what programs such as the manual page viewer (<code>man</code>) use to display information one page at a time.</p>
<p>The <code>PS1</code> (prompt level 1) controls your shell prompt. Here <code>\h</code> means the hostname, <code>\w</code> the working directory and <code>\$</code> is the appropriate prompt symbol (<code>$</code> for normal users, <code>#</code> for root). This gets you a default prompt that looks like <code>alpine310:~$ </code> (note the space after the dollar sign, which is also in the PS1). Let's add the username: change the line to <code>export PS1='\u@\h:\w\$ '</code>. When you log out and in again, your prompt will now be <code>vagrant@alpine310:~$ </code>.</p>
<p>While you're here, you can <code>export EDITOR=nano</code> so that every user gets nano instead of vi as their default editor. Then save the file (Control+X in nano).</p>
<ul>
<li>Research online what <code>umask 022</code> does, note that the number is in base 8.</li>
</ul>
<h2><a class="header" href="#create-a-user-and-a-group" id="create-a-user-and-a-group">Create a user and a group</a></h2>
<p>Create a new user with <code>sudo adduser NAME</code> - I'm going to be using <code>fred</code> as an example name in these notes. When it asks for a password, you can just use <code>fred</code> or something; it will complain about the password being too short but it will create the user anyway.</p>
<p>Check the user and group files with <code>tail /etc/passwd</code> and <code>tail /etc/group</code> to check that the new user has been created - <code>tail</code> displays the last 10 lines of a file by default; <code>tail -n N FILE</code> would display the last N lines. Your new user <code>fred</code> (or whatever you called them) should appear in both files. Also check with <code>ls -l /home</code> that the home directory for Fred exists and is set to the correct user and group.</p>
<p>Time to change user: <code>su fred</code> and enter the password. Notice that the prompt has changed to <code>fred@alpine310:/home/vagrant$</code> (at least if you started off in that folder). So the user has changed, and because <code>/home/vagrant</code> is no longer the current user's home directory, it gets written out in full. Run <code>cd</code> to go home followed by <code>pwd</code> and check that you are now in <code>/home/fred</code> or whatever you called your new user.</p>
<p>Next, create a user <code>george</code> (or some other name) add both your two new users, but not <code>vagrant</code>, to the group <code>users</code> (which already exists) as described in the video. Note: <code>fred</code> cannot use sudo, so you have to exit his terminal to get back to one running as vagrant for this.</p>
<h2><a class="header" href="#explore-file-permissions" id="explore-file-permissions">Explore file permissions</a></h2>
<p>As user <code>fred</code> (or whatever you called your first new user), set up your home directory using what you learnt in the videos so that</p>
<ul>
<li>You can do everything (rwx).</li>
<li>Members of the <code>users</code> group can list files and change to your home directory, but not add/remove files. You will need to change the group of your home directory to <code>users</code> for this, as described in the videos.</li>
<li>Everyone else cannot do anything with your home directory.</li>
</ul>
<p>Create a file in your home directory, e.g. <code>nano readme.txt</code> then add some content.</p>
<p>Check, by using <code>su USERNAME</code> to log in as the different users, that:</p>
<ul>
<li><code>george</code> can view Fred's home directory but not create files there; </li>
<li><code>george</code> can view but not edit Fred's readme file; </li>
<li><code>vagrant</code> cannot list files in or enter Fred's home directory at all. What happens when you try?</li>
</ul>
<p><em>Of course, vagrant can use sudo to get around all these restrictions. Permissions do not protect you from anyone who can become root.</em></p>
<p>Also as <code>fred</code>, make a <code>private</code> subdirectory in your home folder that no-one but you can access (read, write or execute). Create a file <code>secret.txt</code> in there with <code>nano private/secret.txt</code> as user <code>fred</code> from Fred's home directory, and put something in it. Do not change any permissions on <code>secret.txt</code> itself.</p>
<p>Check as George that you can see the folder itself, but not cd into it nor list the file. Check that even knowing the file name (<code>cat /home/fred/private/secret.txt</code>) as George doesn't work.</p>
<p>Using <code>ls -l</code> as Fred in both <code>~</code> and <code>~/private</code>, compare the entries for the files <code>~/readme.txt</code>, <code>~/private/secret.txt</code> and the folder <code>~/private</code>. Why do the groups of the two files differ?</p>
<p>Note that, even though the secret file has read permissions for everyone by default, George cannot read it. The rule is that you need permissions on the whole path from <code>/</code> to a file to be able to access it.</p>
<p><em>This is another reminder that if you want to store coursework on a lab machine, then put it in a folder that is only accessible to you. Other students can read your home directory by default, and they would be able to steal your work and submit it as their own otherwise: this has happened in the past.</em></p>
<p><em>Altenatively you could remove permissions from everyone else on your home directory there, but this prevents you from being able to share files in specific folders that you do want to share with other students.</em></p>
<h2><a class="header" href="#setuid" id="setuid">Setuid</a></h2>
<p>We are going to create a file to let George (and others in the users group) send Fred messages which go in a file in his home directory.</p>
<p>As Fred, create a file <code>message-fred.c</code> in your home directory and add the following lines:</p>
<pre><code class="language-C">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

const char *filename =&quot;/home/fred/messages.txt&quot;;

int main(int argc, char **argv) {
  if (argc != 2) {
    puts(&quot;Usage: message-fred MESSAGE&quot;);
    return 1;
  }
  FILE *file = fopen(filename, &quot;a&quot;);
  if (file == NULL) {
    puts(&quot;Error opening file&quot;);
    return 2;
  }
  int r = fputs(argv[1], file);
  if (r == EOF) {
    puts(&quot;Error writing message&quot;);
    return 2;
  }
  r = fputc('\n', file);
  if (r == EOF) {
    puts(&quot;Error writing newline&quot;);
    return 2;
  }
  fclose(file);
  return 0;
}
</code></pre>
<p>Compile it with <code>gcc -Wall message-fred.c -o message-fred</code> (you should not get any warnings) and check with <code>ls -l</code>, you will see a line like</p>
<pre><code>-rwxr-xr-x    1 fred     fred         19984 Oct 28 13:26 message-fred
</code></pre>
<p>These are the default permissions for a newly created executable file; note that gcc has set the three <code>+x</code> bits for you. Still as Fred, run <code>chmod u+s message-fred</code> and check the file again: you should now see <code>-rwsr-xr-x</code> for the file permissions. The <code>s</code> is the setuid bit.</p>
<p>As George (<code>su george</code>), go into Fred's home directory and run <code>./message-fred &quot;Hi from George!&quot;</code>. The quotes are needed here because the program accepts only a single argument.</p>
<p>Now run <code>ls -l</code> and notice that a <code>messages.txt</code> has appeared with owner and group <code>fred</code>. Check the contents with <code>cat messages.txt</code>. Although George cannot create and edit files in Fred's home directory himself (he can't edit <code>messages.txt</code> for example, although he can read it), the program <code>message-fred</code> ran as Fred, which let it create the file. George can send another message like this (<code>./message-fred &quot;Hi again!&quot;</code>), which gets appended to the file: try this out.</p>
<p>This shows how setuid programs can be used to allow other users to selectively perform specific tasks under a different user account.</p>
<p><strong>Warning</strong>: writing your own setuid programs is extremely dangerous if you don't know the basics of secure coding and hacking C programs, because a bug in such a program could let someone take over your user account. The absolute minimum you should know is the contents of our security units up to and including 4th year.</p>
<p>A general task for a security analyst might be finding all files with the setuid bit set on a system. You can try this yourself, but return to a vagrant shell first so that you're allowed to use sudo:</p>
<pre><code>sudo find / -perm /4000
</code></pre>
<p>You might get some errors relating to <code>/proc</code> files, which you can ignore: these are subprocesses that find uses to look at individual files.</p>
<p>Apart from <code>message-fred</code>, on alpine there are four such files by default: <code>sudo</code>, <code>mount</code>, <code>umount</code> and <code>bbsuid</code>. The first one you already know; look up what the next two do and think about why they are setuid. Specifically, what kinds of (un)mounting are non-root users allowed to do according to the manual pages?</p>
<p>The last one is busybox' general-purpose setuid helper. For example,</p>
<pre><code>ls -l /bin | grep bbsuid
</code></pre>
<p>shows that <code>/bin/su</code> is in fact a link to bbsuid on this system (a symlink to a setuid program inherits the setuid property). <code>grep STRING</code> here filters its input and only returns lines containing the string (or regular expression).</p>
<p>Have a look at the output of the following:</p>
<pre><code>ls -l /usr/bin | grep bbsuid
</code></pre>
<p>Look up what these programs do and think about why they have to be setuid root.</p>
<p>Also have a look at the <a href="https://github.com/alpinelinux/aports/blob/master/main/busybox/bbsuid.c">source code of bbsuid</a>: it's only around 100 lines of C and all it does is check that you're calling it from an approved filename, then launch busybox (still as root) to handle the command. The check is important because anyone can make a symlink to bbsuid and call it say <code>rm</code>, and if bbsuid didn't check for this then it would allow anyone to remove any file on the system as root.</p>
<h2><a class="header" href="#sudo" id="sudo">Sudo</a></h2>
<p>Make sure your terminal is running as <code>fred</code> and try a <code>sudo ls</code>. You will see a general message, you will be asked for your password, and then you will get the error <code>fred is not in the sudoers file.  This incident will be reported.</code> (This means that an entry has been logged in <code>/var/log/messages</code>.)</p>
<p>So, <code>fred</code> can currently not use sudo. Switch back to <code>vagrant</code> and run the command <code>sudo cat /etc/sudoers</code>. Everything is commented out except <code>root ALL=(ALL) ALL</code> and the last line <code>#includedir /etc/sudoers.d</code> (this is not a comment!) which contains a single file <code>vagrant</code> with the line <code>vagrant ALL=(ALL) NOPASSWD: ALL</code> which is why vagrant can use sudo in the first place.</p>
<p>However, note the commented lines such as</p>
<pre><code># %wheel ALL=(ALL) NOPASSWD: ALL
# %sudo ALL=(ALL) ALL
</code></pre>
<p>If uncommented, the first one would let everyone in group wheel run commands using sudo (this is the default on some other linux distributions), whereas the second one would allow everyone in the group <code>sudo</code> to do this, but would prompt for their own password beforehand.</p>
<p>Let's allow people in the users group to reboot the machine. Open a root shell with <code>sudo su</code> as vagrant; this is so we don't get locked out if we break sudo.</p>
<p>Edit the sudoers file with <code>nano /etc/sudoers</code> as root, and add the following line:</p>
<pre><code>%users ALL=(ALL) /sbin/reboot
</code></pre>
<p>and save the sudoers file.</p>
<p>If you read the comment at the top of the file, it suggests using <code>visudo</code> to edit the file. Since we don't want to use vi, we can instead check the syntax with <code>visudo -c</code> and check that we get &quot;parsed OK&quot;; if not then we edit the file again to fix it (this is why we opened a root shell: if there's a syntax error in the file, sudo would refuse to run at all).</p>
<p>You can now switch back to <code>fred</code> (check the prompt to make sure you are Fred) and do <code>sudo reboot</code>. After asking for Fred's password, the virtual machine will now reboot, which you notice because you get kicked out of your ssh connection. Another <code>vagrant ssh</code> after a few seconds will get you back in again.</p>
<h2><a class="header" href="#mounting" id="mounting">Mounting</a></h2>
<p>However, your <code>/vagrant</code> folder will now not work properly, because when vagrant starts the VM it will run some commands as root automatically, but when you manually reboot then they don't get run again. Specifically, in the Vagrantfile:</p>
<pre><code>config.vm.provision :shell, run: 'always', inline: &lt;&lt;-SHELL
    umount /vagrant
    /sbin/mount.vboxsf -o uid=1000 -o gid=1000 vagrant /vagrant
    chmod go+rx /vagrant
SHELL
</code></pre>
<p>This is a workaround for a bug in the interface between virtualbox (that vagrant uses to run the VM) and alpine linux: although the shared folder is mounted automatically, it gets the wrong permissions and only root can use it.</p>
<p>To fix this, you can either run the three commands as root (with sudo) or you can leave the VM and do <code>vagrant halt</code> followed by <code>vagrant up</code>, which will have vagrant reboot the machine again and re-run the commands indicated as <code>run: 'always'</code> in the Vagrantfile. (Commands without this flag only run when a VM is set up for the first time.)</p>
<h1><a class="header" href="#git-part-2" id="git-part-2">Git, part 2</a></h1>
<p>In this exercise we will set up and use a git account on a remote provider. The &quot;big 3&quot; for hosting git repositories are:</p>
<ul>
<li><a href="https://github.com">github.com</a></li>
<li><a href="https://gitlab.com">gitlab.com</a></li>
<li><a href="https://bitbucket.org">bitbucket.org</a></li>
</ul>
<p>This exercise is based on github, as this is the most popular provider, but you can use one of the other two if you want as well (the slides show the equivalent version for gitlab) - although the web user interface and some advanced features are different, interacting with all three on the command line is identical and all three offer unlimited private and public repositories (within reason).</p>
<h2><a class="header" href="#set-things-up" id="set-things-up">Set things up</a></h2>
<p>Go to <a href="https://github.com">github.com</a> and register with a username, an e-mail address and a password. You might have to click a confirmation link in an e-mail sent to you.</p>
<p>We are going to use git over SSH, so you need to let git know your public key (remember, you never give anyone your private key!). Click the icon in the top right corner of the screen that represents your avatar (you can of course set a custom one if you like) and choose <em>Settings</em> in the menu, then on the settings page choose <em>SSH and GPG keys</em>.</p>
<p>Choose <em>New SSH key</em>, and paste your SSH public key in the <code>Key</code> box - this is the file <code>~/.ssh/id_ed25519.pub</code> that you created in the last activity. (The file <code>id_ed25519</code> without <code>.pub</code> in the same folder is your private key, and you never paste that anywhere.) Give your key a title if you like, then add it with the green button. Github supports all common SSH key formats, but will warn you if you do something silly like upload a private key or a key in an outdated and weak cipher.</p>
<div class="advanced container">
<header><span class="advanced-title"></span></header>
<div class="container-content">
<p>If you have many devices (desktop, laptop) that you work from and many servers (github, gitlab, lab machine etc.) that you connect to, how do you manage keys?</p>
<p>Using the same public key for different services is not a security problem: even if one service gets hacked and you connect to it while it's under the hacker's control, that does not leak your private key. Unlike passwords, you can safely reuse public keys.</p>
<p>However, reusing public keys can be a privacy problem, because every service that you use the same public key (or e-mail address, or phone number etc.) can potentially work with the others to know that you are the same individual. It is no problem to use different keypairs for different services, in which case you probably want a block in your <code>~/.ssh/config</code> file with something like </p>
<pre><code>Host github.com
    IdentityFile FILENAME
</code></pre>
<p>to tell SSH that the key for this host is named something other than the default <code>id_ed25519</code>.</p>
<p>You can copy the same private key to different devices that you own, or you can set up a different key for each device and add the public keys of all of them to github and the different providers. This is a security/convenience trade-off, the security angle being what happens if one of your devices gets stolen or otherwise compromised.</p>
<p>If you are running this exercise on an alpine VM hosted on a lab machine, then because the lab machine does not belong to you, I would not use the same private key on your VM than on your own computer, especially not if you use your own computer to access other services than the university. If you want to use Github both from your own machine and from the lab machines, then create a separate keypair for each and enrol both the public keys with Github.</p>
</div>
</div>
<p>I am assuming that you will be running the git commands in the rest of this section on an alpine linux VM, either on your machine or on a lab machine, however if you have git installed on your own machine directly (which is a good idea) then you can run this exercise there too.</p>
<h2><a class="header" href="#a-note-on-naming" id="a-note-on-naming">A note on naming</a></h2>
<p>When git first appeared, whenever you created a repository you started with one branch called <code>master</code>. Different workflows and branch naming conventions appeared over time (we will see one of these in the next activity).</p>
<p>As far as git is concerned, a branch name is just a string and any other name would do just as well (as long as it does not contain spaces, slashes or a few other special characters). As far as humans go, in 2020 it came to developers' attention that the term <code>master</code> is sometimes used in problematic ways in engineering in general and computing in partciular, specifically, a system where several components perform similar roles but one of them is the authoritative one in case of discrepancy has historically been called a <em>master/slave</em> system.</p>
<p>The git developers' first reaction was to make it easier to choose a different name for your first branch; the latest version of git prints a message on how to do this when you create a repository (the configuration setting is <code>init.defaultBranch</code>) and the online providers such as github offer a text field for this too. At the moment, <code>main</code> seems to be the most popular alternative name for the first branch, but at the time of writing there does not seem to be a clear consensus yet. I have seen both <code>default</code> and <code>root</code> suggested as first branch names, neither of which seems to have gained much traction though. Another contender for workflows which use a <code>develop</code> branch anyway is to use that as the initial branch. The latest post on the matter from <a href="https://sfconservancy.org/news/2020/jun/23/gitbranchname/">software freedom conservancy</a> is dated June 2020 and states that the matter is &quot;currently being discussed on our mailing list&quot;.</p>
<p>There has been some debate about whether the name &quot;master&quot; in git traces back to <em>master/slave</em> or another, less problematic use of word e.g. the phrase <em>master copy/master recording</em> from the music industry - the most authoritative source I can find on the matter is <a href="https://git.github.io/rev_news/2020/07/29/edition-65/">git rev news 65, July 2020</a> from the git developers themselves, which also states that a change of the default branch name might happen in Git 3.0 (the version installed in Alpine at the time of writing is 2.30.0).</p>
<p>There is another line of argument that the word <em>master</em> as a default branch name (and thus something developers will refer to a lot) is inherently problematic even if it came from a different origin than <em>master/slave</em>. This is a complicated issue as, among other things, half the cohort taking Software Tools is probably on a <em>Master's Degree</em> and one of the criteria for a first-class mark is showing <em>mastery</em> of the unit material - all terms that will be much harder to change than a simple repository name which is one line of commands to change. Git does not care what your branches are called after all, one string is as good as another (as long as it doesn't contain special characters or spaces).</p>
<p>However, a fresh installation of git will still call the branch <code>master</code> unless you change a configuration setting, and any book, tutorial, forum or stackexchange post online written about git before around mid-2020 will refer to <code>master</code> so there is currently no way around knowing that in the context of git, the term <code>master</code> refers to a branch with a particular role, but as a future developer you should also have an understanding of the community and conventions around your tools and you should definitely know that there is a currently ongoing discussion around this term.</p>
<p>For the 2020-21 academic year, I have decided to go with <code>master</code> for this unit as I don't feel it's my job to pre-empt a decision on the new default name - github is in favour of <code>main</code> but the git developers do not seem to have made a final decision yet; and because you will encounter the term <code>master</code> in git itself and in a lot of existing repositories and documentation (including the official <a href="https://git-scm.com/book/en/v2">git book</a> at the time of writing); it will be easy enough to update these notes for 2021-22 if everyone has switched to <code>main</code> or something else by then.</p>
<p>For your own repositories, you are free to choose whatever name you like, and you can configure this with the command</p>
<pre><code>git config --global init.defaultBranch NAME
</code></pre>
<p>and then follow the rest of the git exercises, mentally replacing <code>master</code> by <code>main</code> or your choice of other name. </p>
<p>When you create a repository on github, the default name you get depends on your settings, which seems to depend on when you created your account - if you create an account today, you will get <code>main</code> as the default name but on my account (which has been around for years) I still get <code>master</code>. The page you want to check while logged in to github is https://github.com/settings/repositories; if you get <code>main</code> as your default then please use that in the rest of this tutorial.</p>
<p>To finish with a quote from the git book:</p>
<blockquote>
<p>The &quot;master&quot; branch in Git is not a special branch. It is exactly like any other
branch. The only reason nearly every repository has one is that the git init
command creates it by default and most people don't bother to change it.</p>
</blockquote>
<h2><a class="header" href="#create-a-repository" id="create-a-repository">Create a repository</a></h2>
<p>On the main page, you should see an empty <em>Repositories</em> bar on the left, with a new button. Use that to create a repository, on the next page give it a name and tick the <em>Add a README file</em> box.</p>
<p>On the repository page, there is a green <em>Code</em> button. Clicking that opens a box with three tabs: <em>HTTPS</em>, <em>SSH</em> and <em>GitHub CLI</em>.</p>
<p>Each repository has a two-part name: the first part is the owner's github username, the second part is the repository name. For example, the repository for this unit is called <code>cs-uob/COMS10012</code>. There are two ways to interact with a remote repository:</p>
<ul>
<li>Via HTTPS. This is ok if you are just cloning a public repository, as it does not require any authentication. To interact with a private repository or to push files, HTTPS requires username/password authentication, and we can do better than that.</li>
<li>Via SSH, using keys. This is the recommended way to use Git.</li>
</ul>
<p>Click the SSH tab and copy the URL there - it should be something like <code>git@github.com:USERNAME/REPONAME.git</code>.</p>
<p>On the command line, run the command <code>git clone git@github.com:USERNAME/REPONAME.git</code> where you replace USERNAME and REPONAME with the parts from the SSH tab of your repository. Git clones your repository and puts the content in a subfolder named after the repository name - you can change this by providing a different folder name as an extra command-line argument to <code>git clone</code>, or you can just move or rename the folder later on.</p>
<p><em>Note: certain OS/ISP/DNS combinations might get you &quot;resource temporarily unavailable&quot; when you try and access github via ssh. The problem is that the actual address is <code>ssh.github.com</code> and not all set-ups correctly pass on the redirection when you try and connect to github directly. If you are experiencing this error, you can either use <code>ssh.github.com</code> in place of <code>github.com</code>, or add an entry in your <code>~/.ssh/config</code> file as follows (if you have to create this file first, make sure it is not writable by anyone except yourself or ssh will refuse to accept it):</em></p>
<pre><code>Host github.com
  Hostname ssh.github.com
  Port 22
</code></pre>
<div class="advanced container">
<header><span class="advanced-title"></span></header>
<div class="container-content">
<p>Notice that git did not ask for your username. It can determine your identity from your public key, as that is stored in your user account.</p>
<p>In the last activity, we configured a name and e-mail address for git commits. When you push commits to github, this information will appear in every commit, but it does not have to match your Github account information - Github will let you push commits with any name you like, as you might be pushing them on behalf of someone else.</p>
</div>
</div>
<p>Go to that folder, and try <code>git remote show origin</code>. Here, <code>origin</code> is the default name of a <em>remote</em>, and the result should look a bit like this:</p>
<pre><code>* remote origin
  Fetch URL: git@github.com:USERNAME/REPONAME
  Push  URL: git@github.com:USERNAME/REPONAME
  HEAD branch: master
  Remote branch:
    master tracked
  Local branch configured for 'git pull':
    master merges with remote master
  Local ref configured for 'git push':
    master pushes to master (up to date)
</code></pre>
<p>The bits about <code>master</code> are to do with branches, which we will discuss in another activity in more detail. <em>You might see <code>main</code> instead of master, in which case please use <code>main</code> instead of <code>master</code> from now on.</em></p>
<div class="advanced container">
<header><span class="advanced-title"></span></header>
<div class="container-content">
<p>You can have several remotes with different names - for example if you fork (create your own copy of someone else's repository) then you get the original one as a second remote named <em>upstream</em>, so you can share changes back with them - this is the way you create new content for the <a href="https://cssbristol.co.uk">CSS website</a> for example.</p>
<p>You can also use folders as remotes: if you want to practice resolving merge conflicts, you could do the following:</p>
<pre><code>mkdir remote
cd remote
git init --bare
cd ..
mkdir user1
git clone remote user1
mkdir user2
git clone remote user2
</code></pre>
<p>This gets you a remote and two &quot;users&quot; in different folders to play with. The remote was set up with <code>--bare</code> so that it does not contain a working copy, but acts as a pure repository.</p>
<p>You can now <code>cd user1</code> to simulate user 1 doing work, and can fetch/push/pull as described below. (Ignore warnings about &quot;upstream&quot;, they will go away once you have committed a file to the repository.) Then you can <code>cd ../user2</code> to switch to a second working copy, which you can pretend is another user on another machine.</p>
<p>If you want to adjust the user names for the commits, then running <code>git config user.name &quot;YOURNAME&quot;</code> and <code>git config user.email &quot;YOUREMAIL&quot;</code> without the <code>--global</code> option from last time changes the settings just for one repository.</p>
</div>
</div>
<p>Do a <code>git status</code> and note that a new line appears compared to last activity:</p>
<pre><code>Your branch is up to date with 'origin/master'.
</code></pre>
<p>This line comes in four versions:</p>
<ul>
<li>Up to date: there have been no commits on your local or the remote repository since you last synchronised.</li>
<li>Ahead of remote: you have made commits locally that you have not yet pushed to the remote.</li>
<li>Behind remote: someone else, or you on a different computer, have made commits to the remote that you do not have on this computer yet.</li>
<li>Diverged from remote: both your computer and the remote have had different commits since the last time you synchronised. </li>
</ul>
<h2><a class="header" href="#practice-the-push-workflow" id="practice-the-push-workflow">Practice the push workflow</a></h2>
<p>For this exercise, you should work in pairs or larger groups.</p>
<p>One person creates a private repository (tick the box to add a README file) and adds everyone else in the group to it. You all need to have an account with the same provider for this to work.</p>
<ul>
<li>On Github, the way to add people to a repository is on the repository page: choose <em>Settings</em> in the top menu, then <em>Manage access</em>. Here you can press <em>Invite a collaborator</em> and enter their Github username. This causes Github to send them an e-mail with a link they need to click to accept the invitation and be added to the repository. <em>Note: you must be logged in to github when you click the link on the invitation e-mail, otherwise you will get an error message.</em></li>
<li>On Gitlab, the place to add people is under <em>Members</em> in the left menu on the repository page, and there are different access levels - give them  <em>Maintainer</em> access to let them push commits.</li>
</ul>
<p>Everyone <code>git clone</code>s the repository to their own alpine VM (or their own machine directly).</p>
<p>Everyone does the following, one person at a time doing all steps (coordinate among each other):</p>
<ol>
<li>Imagine that it is mid-morning and you are starting on a day's coding.</li>
<li>First, make sure your terminal is in the folder with your working copy, and type <code>git fetch</code>.
<ul>
<li>If you get no update, then there were no changes on the remote since your last fetch and you are ready to start coding. (This should happen to the first person to do this step.)</li>
<li>If you get output, then there were changes on the remote. Do a <code>git status</code> to see details (everyone except the first person should see this). Notice the line <code>behind origin/master ... can be fast-forwarded.</code> which means you just need to <code>git pull</code> and you will get the latest version of the files. Do a <code>git log</code> too to see the last person's commit message.</li>
</ul>
</li>
<li>Do some coding: make a change to the repository - add or change a file, then commit your changes. You can use <code>nano FILENAME</code> to create and edit a file in your terminal, if you have installed it as described in the last activity.</li>
<li>Run the following push workflow to push your changes to the remote:
<ol>
<li>Do a <code>git fetch</code> to see if there were any remote changes (there shouldn't be, for this exercise).</li>
<li>Do a <code>git status</code> and make sure you are <code>ahead of origin</code>, not <code>diverged</code>.</li>
<li>Do a <code>git push</code> to send your changes to the remote.</li>
</ol>
</li>
</ol>
<p>You can now code as a team, as long as only one person at a time is working - clearly not ideal.</p>
<h2><a class="header" href="#resolve-a-fake-conflict-part-one" id="resolve-a-fake-conflict-part-one">Resolve a fake conflict, part one</a></h2>
<p>Produce a &quot;fake&quot; conflict as follows:</p>
<ol>
<li>Two team members make sure they are <code>up to date</code> with their working copies (do a <code>git pull</code>, then <code>git status</code>). This represents you both starting coding in the morning.</li>
<li>One member adds or changes one file, then commits this change and pushes it by running the whole push workflow (fetch, status - check you're ahead, push).</li>
<li>At the same time as the first member is doing step 2, the second member adds or changes a different file, then commits this change. This represents two team members working in parallel, with the member one being the first one to complete their work and push a commit back to the remote.</li>
<li>The second member starts the push workflow with <code>git fetch</code>, then <code>git status</code>. Notice you have <code>diverged</code>. (If you were to try to <code>git push</code>, with or without fetching this would produce an error.)</li>
</ol>
<p>The commit graph of member two looks something like this:</p>
<p><img src="act2/../resources/before-rebase.png" alt="diagram of commits before rebase" /></p>
<p>One way to resolve this conflict is a <em>rebase</em>, which is pretending that member two had actually fetched the <code>one</code> commit before starting their own work. The command for this which member two types is <code>git rebase origin/master</code> which means <em>pretend that everything in origin/master happened before I started my local changes</em> and gives the following graph:</p>
<p><img src="act2/../resources/after-rebase.png" alt="diagram of commits after rebase" /></p>
<p>Indeed, if member two does a <code>git status</code> after the rebase, they will see <code>ahead of origin/master by 1 commit</code> and they can now <code>git push</code> to send their local changes to the remote repository.</p>
<p>Different companies and teams have different opinions on when a rebase makes sense: some places forbid rebasing like this entirely, at least for work that is genuninely shared between different people. There is more or less a general consensus that you should not rebase when different people were editing the same files, but it is a technique worth knowing about for conflicts like the one you just created where different people have edited different files, as it makes for a cleaner commit graph.</p>
<h2><a class="header" href="#fake-conflicts-part-two" id="fake-conflicts-part-two">Fake conflicts, part two</a></h2>
<p>The other way to fix conflicts - and the only one that some people will use - is a merge. Let's do another fake conflict, but resolve it with a merge this time:</p>
<ol>
<li>Two team members both get their repositories up to date with the remote. If you have just followed the instructions above then team member one has to <code>git pull</code> and team member two is already up to date because they have just pushed; both team members should check with <code>git fetch</code> then <code>git status</code> that they are <code>up to date</code>.</li>
<li>Like before, team member one edits one file, commits it and does the whole push workflow (fetch, status - check you're ahead, push). The second team member at the same time, without another fetch, edits a different file and commits.</li>
<li>The second team member starts the push workflow: fetch, status - notice you've <code>diverged</code>.</li>
</ol>
<p>The second member's commit graph looks similar to the previous one before the rebase, perhaps with more commits in place of the <em>initial</em> one.</p>
<p>The second member is about to do a merge, which can either succeed (as it should here, because different people edited different files) or fail with a merge conflict (for example if different people edited the same file). If a merge succeeds, then git will make a merge commit and will drop them into their system's default editor, which is normally <code>vi</code>. Because we don't want to learn that right now, the second member should type <code>echo $EDITOR</code> in their shell and see what they get - if they get <code>nano</code> then they're fine, if they get an empty line then they should do <code>export EDITOR=nano</code>.</p>
<p>The second team member types <code>git pull</code>. Since this is a fake conflict (different files), this gets you into your editor, and you can see that on the first line is a suggested commit message starting with <code>Merge branch master</code>, which it is conventional to accept without changes - exit your editor again. Git replies <code>Merge made by the recursive strategy.</code> and your commit graph now looks something like this (the <code>...</code> stands for the last commit from the previous section):</p>
<p><img src="act2/../resources/after-merge.png" alt="diagram of commits after merge" /></p>
<h2><a class="header" href="#resolving-a-real-conflict" id="resolving-a-real-conflict">Resolving a real conflict</a></h2>
<p>And next, we'll practice dealing with a real conflict, where two people have edited the same file.</p>
<ol>
<li>Two team members get their repositories synchronised again: everyone does a <code>git pull</code>.</li>
<li>Team member one creates a file called <code>README.md</code> or edits it if it already exists, and adds a line like <code>Created by NAME</code> with their own name. Then they commit this change and run the push workflow: <code>git fetch</code>, <code>git status</code>, check they're <code>ahead</code>, <code>git push</code> to the remote.</li>
<li>Team member two, without fetching the latest commit, creates the same <code>README.md</code> file and adds a line <code>Created by NAME2</code> and commits this to their local repository. This simulates two people working on the same files in parallel since they both last fetched, and one of them (member one in this case) is the first to get their changes back to the remote.</li>
<li>Team member two starts the push workflow: <code>git fetch</code>, <code>git status</code> and notice that you have <code>diverged</code> again.</li>
<li>Run <code>git pull</code> as member two. You should see the following message:</li>
</ol>
<pre><code>CONFLICT (add/add): Merge conflict in README.md
Auto-merging README.md
Automatic merge failed; fix conflicts and then commit the result.
</code></pre>
<p>Open the file, for example <code>nano README.md</code> and notice that git has annotated it:</p>
<pre><code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD
Created by NAME2.
=======
Created by NAME1.
&gt;&gt;&gt;&gt;&gt;&gt;&gt; b955a75c7ca584ccf0c0bddccbcde46f445a7b30
</code></pre>
<p>The lines between <code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</code> and <code>=======</code> are the local changes (team member two) and the ones from <code>======</code> to <code>&gt;&gt;&gt;&gt;&gt;&gt; ...</code> are the ones in the commit fetched from the remote, for which the commit id is shown.</p>
<p>Member two now has to resolve the conflict by editing the file to produce the version they would like to commit. For example, you could remove all the offending lines and replace them with <code>Created by NAME1 and NAME2.</code></p>
<p>Member two can now do the following:</p>
<ul>
<li><code>git add README.md</code> (or whatever other files were affected).</li>
<li><code>git commit</code>. You could give a message directly, but a commit without a <code>-m</code> drops you into your editor and you'll see that git is suggesting <code>Merge branch master ...</code> as a default message here. It is conventional to leave this message as it is, just exit your editor without any changes.</li>
<li>Run another push workflow: <code>git fetch</code>, <code>git status</code> and notice you are now <code>ahead by 2 commits</code>: the first one was the work you did, the second is the merge commit. You're ahead, so finish the workflow with <code>git push</code>.</li>
</ul>
<p>Your commit graph looks the same as for the last merge that you did. </p>
<p>If you look at the repository's page on Github (<code>https://github.com/USERNAME/REPONAME</code>, where <code>USERNAME</code> is the name of the user who created the repository), then you can click on <em>Insights</em> in the top bar then <em>Network</em> on the left menu to see the commit history for the repository as a graph. Hovering over a commit node shows the committer, the message and the commit hash - and clicking on a node takes you to a page where you can see which changes were made in this commit.</p>
<p>On the main Github page for the repository, you can also click the clock icon with a number in the top right (on a wide enough screen it also shows the word <em>commits</em>) to go to a page showing all the commits on your repository in chronological order.</p>
<h1><a class="header" href="#pipes" id="pipes">Pipes</a></h1>
<p>The command <code>ls | head</code> runs ls and head and pipes the standard output of ls into the standard input of head.</p>
<p>The following shell commands are particularly useful in pipes:</p>
<ul>
<li><code>cat [FILENAME [FILENAME...]]</code> writes the contents of one or more files to standard output. This is a good way of starting a pipe. If you leave off all the filenames, cat just reads its standard input and writes it to standard output.</li>
<li><code>head [-n N]</code> reads its standard input and writes only the first N lines (default is 10 if you leave the option off) to standard output. You can also put a minus before the argument e.g. <code>head -n -2</code> to <em>skip the last 2 lines</em> and write all the rest.</li>
<li><code>tail [-n N]</code> is like head except that it writes the last N lines (with a minus, it skips the first N ones).</li>
<li><code>sort</code> reads all its standard input into a memory buffer, then sorts the lines and writes them all to standard output.</li>
<li><code>uniq</code> reads standard input and writes to standard output, but skips repeated lines that immediately follow each other, for example if there are three lines A, A, B then it would only write A, B but if it gets A, B, A it would write all three. A common way to remove duplicate lines is <code>... | sort | uniq | ...</code>.</li>
<li><code>grep [-iv] EXPRESSION</code> reads standard input and prints only lines that match the regular expression to standard output. With <code>-i</code> it is case-insensitive, and with <code>-v</code> it only prints lines that do <em>not</em> match the expression.</li>
<li><code>sed -e COMMAND</code> reads lines from standard input, transforms them according to the command and writes the results to standard output. <code>sed</code> has its own command language but the most common one is <code>s/SOURCE/DEST/</code> which changes substrings matching the source regular expression into the destination one.</li>
<li><code>wc [-l]</code> stands for word count, but with <code>-l</code> it counts lines instead. Putting a <code>wc -l</code> on the very end of a pipe is useful if you just want to know how many results a particular command or pipe produces, assuming the results come one per line.</li>
</ul>
<p>All these commands actually take an optional extra filename as argument, in which case they read from this file as input. For example, to display the first 10 lines of a file called <code>Readme.txt</code>, you could do either <code>cat Readme.txt | head</code> or <code>head Readme.txt</code>.</p>
<h2><a class="header" href="#word-list-exercises---pipes-and-regular-expressions" id="word-list-exercises---pipes-and-regular-expressions">Word list exercises - pipes and regular expressions</a></h2>
<p>Most linux distributions come with a dictionary file <code>/usr/dict/words</code> that contains a list of English words in alphabetical order, for use in spell-checking programs. The list includes a selection of proper nouns, for example countries and cities. Alpine linux, true to its principles of being minimal, omits this file - but you can download one yourself with</p>
<pre><code>wget https://users.cs.duke.edu/~ola/ap/linuxwords -O words
</code></pre>
<p><code>wget</code> is one of two utilities for downloading files, the other being <code>curl</code>. Note that the option for output file name is a capital O, not a lowercase o or a zero.</p>
<p>Find one-line commands, possibly with pipes, to print the following to your terminal. You can either start each command with <code>cat words | ...</code> or do it without cat by providing the words file as an argument to the first command in your pipeline.</p>
<p><em>If English is not your native language, ignore the guessing part - it is not assessed.</em></p>
<ul>
<li>The first word in the file. <em>Can you guess what it will be, it is a city in Europe?</em></li>
<li>The last word in the file. <em>Can you guess this one, another city in Europe?</em></li>
<li>The number of words in the words file - there is one word per line.</li>
<li>The 6171st word in the file. <em>Can you read my mind and guess this word directly?</em></li>
<li>All words containing the letter Q, capitalised. (A regular expression containing a string of one or more letters matches all strings that contain the expression as a substring.)</li>
<li>All words starting with the letter X. The regular expression <code>X</code> would match an X anywhere in the word, but <code>^X</code> matches an X only at the start of the string.</li>
<li>All words ending in j. (The expression <code>'j$'</code> matches a j only at the end of the string, but you have to single-quote it to stop the shell from interpreting the dollar sign). <em>Can you guess the word - it is a city in eastern Europe?</em></li>
<li>The number of words containing the letter Q, ignoring case (e.g. capitalised or not).</li>
<li>The first five words containing the letter sequence <code>cl</code>.</li>
<li>All words containing the sequence &quot;kp&quot;, but not &quot;ckp&quot;. <em>Can you guess any of these?</em></li>
<li>The last 15 words of exactly two letters. The expression <code>.</code> (period) matches a single character, and <code>'^...$'</code> for example would match all strings of the format <em>exactly three characters between start and end of string</em>. You need to quote it because of the dollar sign.</li>
<li>All words from the first 100 words on the list, which contain the letter y.</li>
<li>The first five words that are among the last 100 words on the list, and contain the letter y (whether capitalised or not).</li>
<li>All three-letter words with no vowels (aeiou).The regular expression <code>'[aeiou]'</code> matches any string that contains one of the bracketed characters; you need quotes to stop the shell from interpreting the brackets. Remember to exclude words with capitalised vowels as well. <em>There are 12 of these, can you guess them all before looking?</em></li>
<li>All words of exactly 7 letters, where the third one is an e and the word ends &quot;-ded&quot;. <em>This kind of search is really useful for crosswords. There are 9 words of this form, can you guess them?</em></li>
</ul>
<p>Bonus regular expression question:</p>
<ul>
<li>Find all words that start with a P (whether capitalised or not), and contain at least four instances of the letter a. Putting a <code>*</code> after something in a regular expression searches for <em>any number of repetitions of this, including 0</em> so for example <code>'a*'</code> would find words with any number of the letter a, including 0 (which is not what you want here). You need single quotes to stop the shell from expanding the <code>*</code>. <em>Can you guess the words? There are essentially four of them, two demonyms (for some reason one of them has a plural in the list, the other doesn't), and two nouns which are not proper nouns.</em></li>
</ul>
<h1><a class="header" href="#activity-3" id="activity-3">Activity 3</a></h1>
<h2><a class="header" href="#videos-2" id="videos-2">Videos</a></h2>
<table><thead><tr><th>Video</th><th align="right">Length</th><th>Mediasite</th><th>Slides</th></tr></thead><tbody>
<tr><td><a href="https://ams-hsta-ims-ond.mediasite.com/MediasiteDeliver/vol01/bristoluniversity/MP4Video/f36e52ac-9803-4ea4-99f0-11d9f7e5b653.mp4/QualityLevels(698000)">Git, part 3</a></td><td align="right">19 minutes</td><td><a href="https://mediasite.bris.ac.uk/Mediasite/Play/85ae77ff8d3243fda8b87f147dc041941d">mediasite</a></td><td><a href="act3//COMS10012/slides/Git%203.pdf">slides</a></td></tr>
<tr><td><a href="https://ams-hsta-ims-ond.mediasite.com/MediasiteDeliver/vol01/bristoluniversity/MP4Video/4c809979-5293-48ea-b7ab-b8fffad18195.mp4/QualityLevels(698000)">inodes</a></td><td align="right">28 minutes</td><td><a href="https://mediasite.bris.ac.uk/Mediasite/Play/a3d5a630d65b43d5a052422bb265ee561d">mediasite</a></td><td><a href="act3//COMS10012/slides/inodes.pdf">slides</a></td></tr>
<tr><td><a href="https://ams-hsta-ims-ond.mediasite.com/MediasiteDeliver/vol01/bristoluniversity/MP4Video/4cec82bd-2d0f-4ec9-a7ab-66b89eabf4c1.mp4/QualityLevels(698000)">shell scripting</a></td><td align="right">38 minutes</td><td><a href="https://mediasite.bris.ac.uk/Mediasite/Play/f2f15c55f3c74b7a91a0c35eaf6aea311d">mediasite</a></td><td><a href="act3//COMS10012/slides/shell%20scripting.pdf">slides</a></td></tr>
</tbody></table>
<h2><a class="header" href="#exercises-2" id="exercises-2">Exercises</a></h2>
<ul>
<li><a href="act3/./git3.html">Git, part 3</a></li>
<li><a href="act3/./stat.html">inodes and system calls</a></li>
<li><a href="act3/./script.html">shell scripting</a></li>
</ul>
<h1><a class="header" href="#git-part-3" id="git-part-3">Git, part 3</a></h1>
<p>In this activity you will practice Git the way it is used in real teams. You will need to form a group for this activity, ideally more than two students.</p>
<h2><a class="header" href="#set-up" id="set-up">Set-up</a></h2>
<p>One member makes a Git repository on one of the online providers, adds the other team members and shares the cloning URL. Everyone clones the repository.</p>
<p>The repository must have at least one commit for the following to work. This condition is satisfied if you chose your provider's option to create a readme file; if not then make a file now, commit it and push.</p>
<h2><a class="header" href="#the-develop-branch" id="the-develop-branch">The develop branch</a></h2>
<p>By default, your repository has one branch named <code>master</code> (or <code>main</code> depending on how you or your provider set it up). But you don't want to do your work on this branch directly. Instead, one team member creates a <code>develop</code> branch with the command</p>
<pre><code>git checkout -b develop
</code></pre>
<p>The team member who created the develop branch should now make a commit on it.</p>
<p>This branch currently exists only in their local repository, and if they try and push they would get a warning about this.
What they need to do is</p>
<pre><code>git push --set-upstream origin develop
</code></pre>
<p>This adds an &quot;upstream&quot; entry on the local develop branch to say that it is linked to the copy of your repository called <code>origin</code>, which is the default name for the one you cloned the repository from.</p>
<p>You can check this with <code>git remote show origin</code>, which should display among other things:</p>
<pre><code>Remote branches:
  develop tracked
  master  tracked
Local branches configured for 'git pull':
  develop merges with remote develop
  master  merges with remote master
Local refs configured for 'git push':
  develop pushes to develop (up to date)
  master  pushes to master  (up to date)
</code></pre>
<p>Everyone else can now <code>git pull</code> and see the branch with <code>git branch -a</code>, the <code>-a</code> (all) option means include branches that only exist on the remote. They can switch to the develop branch with <code>git checkout develop</code>, which should show:</p>
<pre><code>Branch 'develop' set up to track remote branch 'develop' from 'origin'.
Switched to a new branch 'develop'
</code></pre>
<h2><a class="header" href="#feature-branches" id="feature-branches">Feature branches</a></h2>
<p>Every team member now independently tries the following:</p>
<ul>
<li>Make a new branch with <code>git checkout -b NAME</code>, choosing a unique name for their feature branch.</li>
<li>Make a few commits on this branch.</li>
<li>Push your feature branch with <code>git push --set-upstream origin NAME</code>.</li>
<li>Make a few more commits.</li>
<li>Do a simple <code>git push</code> since you've already linked your branch to <code>origin</code>.</li>
</ul>
<p>Since everyone is working on a different branch, you will never get a conflict this way.</p>
<p>Anyone who is a project member can visit the github page can see all the feature branches there, but a normal <code>git branch</code> will not show other people's branches that you've never checked out yourself. Instead, you want to do <code>git branch -a</code>  again that will show you all the branches, with names like <code>remotes/origin/NAME</code> for branches that so far only exist on the origin repository. You can check these out like any other branch to see their contents in your working copy.</p>
<h2><a class="header" href="#merging" id="merging">Merging</a></h2>
<p>When a feature is done, you want to merge it into develop. Everyone should try this, the procedure for this is</p>
<ol>
<li>Commit all your changes and push.</li>
<li>Fetch the latest changes from origin (a simple <code>git fetch</code> does this).</li>
<li><code>git checkout develop</code>, which switches you to the develop branch (the changes for your latest feature will disappear in the working copy, but they're still in the repository). You always merge into the currently active branch, so you need to be on <code>develop</code> to merge into it.</li>
<li><code>git status</code> to see if someone else has updated develop since you started your feature. If so, then <code>git pull</code> (you will be <em>behind</em> rather than <em>diverged</em> because you have not changed develop yourself yet).</li>
<li><code>git merge NAME</code> with the name of your feature branch.</li>
<li>Resolve conflicts, if necessary (see below).</li>
<li><code>git push</code> to share your new feature with the rest of the team.</li>
</ol>
<p>If no-one else has changed <code>develop</code> since you started your branch, or if you have only changed files that no-one else has changed, then the merge might succeed on the first attempt. It's still a good idea to check that the project is in a good state (for example, compile it again) just in case, and fix anything that's broken on the develop branch.</p>
<p>If the merge fails with a conflict, then you need to manually edit all the conflicted files (git will tell you which ones these are, do <code>git status</code> if you need a reminder) and <code>git commit</code> again.</p>
<p>The workflow for merging and resolving conflicts is essentially the same as the one from the last session, but since everyone is developing on a separate branch, the only time when you have to deal with a possible merge conflict is when you are merging your changes into develop - your own branches are &quot;private&quot; and you don't have to worry about hitting a conflict if you quickly want to commit and push your changes as the last thing you do before going home at the end of a long day's work.</p>
<h2><a class="header" href="#pull-requests" id="pull-requests">Pull requests</a></h2>
<p>Pull requests are not a feature of the git software itself, but of the online providers. They let a team discuss and review a commit before merging it into a shared branch such as develop or master. Depending on the provider, branches can also be protected or assigned owners so that only the branch owner or developers with the right permissions can commit on certain branches.</p>
<p>The procedure for merging with a pull request on github, which you should try out:</p>
<ul>
<li>Commit and push your feature branch.</li>
<li>On github.com in your repository, choose <em>Pull Requests</em> in the top bar, then <em>New Pull Request</em> .</li>
<li>Set the <em>base</em> branch as the one you want to merge into, e.g. develop, and the <em>compare</em> branch as the one with your changes. Select <em>Create Pull Request</em>.</li>
<li>Add a title and description to start a discussion, then press <em>Create Pull Request</em> again to create the request.</li>
</ul>
<p>Anyone in the team can now go to <em>Pull Requests</em> in the top bar of the repository page and see the open requests. You can either comment on them, or if it is your role in the team to approve the request for this branch, you can approve the pull request which creates a merge.</p>
<p>Since a pull request is linked to a branch, you can use it for code review as follows:</p>
<ol>
<li>A developer creates a feature branch and submits a pull request.</li>
<li>The reviewer looks at the request. If they find bugs or other problems, they add a comment to the discussion.</li>
<li>The developer can address reviewer comments by making a new commit on their feature branch and pushing it, which automatically gets added to the discussion.</li>
<li>When the reviewer is happy, they approve the request which merges the latest version of the feature branch into the base branch (for example <code>develop</code>).</li>
</ol>
<p>There is just one complication left. Suppose the following happens:</p>
<ul>
<li>Your project starts out with commit <code>develop-1</code> setting up the initial version of the develop branch. Imagine there are two files, A and B.</li>
<li>You create a feature branch and make a commit <code>feature-1</code> which changes only file B.</li>
<li>In the meantime, someone else makes a feature that changes file A, and merges it as <code>develop-2</code> to the develop branch.</li>
</ul>
<p>You are now in the situation that <code>develop-2</code> has (new A, old B) and your <code>feature-1</code> has (old A, new B). Neither of these is what you want, you presumably want (new A, new B). We have met this situation before, but without branches. Graphically:</p>
<p><img src="act3/../resources/pr-before-rebase.png" alt="diagram of commits before rebase" /></p>
<p>The solution here is to <em>rebase</em> your branch onto the latest commit on develop with <code>git rebase develop</code> and fix any conflicts that that causes, which produces the following situation:</p>
<p><img src="act3/../resources/pr-after-rebase.png" alt="diagram of commits after rebase" /></p>
<p>If you now try and push your feature branch, you might get an error because the version of your feature branch on the origin repository still has the old version. The solution here is to force the push, which overwrites the old version, with</p>
<pre><code>git push --force origin BRANCHNAME
</code></pre>
<p>This is a <em>think before you type</em> kind of command because it can break things for other developers if you do it on a shared branch. The basic safety rules are:</p>
<ul>
<li>Only rebase on <em>private</em> branches.</li>
<li>Only force push on <em>private</em> branches, and only if it is absolutely necessary (for example to tidy up a rebase).</li>
</ul>
<p>A private branch is one that you know no-one else is working on, for example your own feature branches.</p>
<p>If you ever get into a situation where you need to rebase or force push on a shared branch such as develop or master, you generally need to make sure that everyone on the team knows what is going on, synchronises their repositories both before and after the dangerous operation, and does not make any commits or pushes while someone is working on it - basically they need, in concurrency terms, an exclusive lock on the whole repository while doing this operation.</p>
<p>This is one reason why the master and develop branches are kept separate - and some workflows even include a third branch called <code>release</code>. If merges into master or release only ever come from the develop branch, then a situation where you need to rebase these branches can never happen.</p>
<p>To summarise, the pull request workflow is:</p>
<ol>
<li>Commit and push your changes.</li>
<li>If necessary, rebase your feature branch on the develop branch.</li>
<li>Create a pull request.</li>
<li>If necessary, participate in a discussion or review and make extra commits to address points that other developers have raised.</li>
<li>Someone - usually not the developer who created the pull request - approves it, creating a merge commit in develop (or master).</li>
</ol>
<h1><a class="header" href="#inodes-and-system-calls" id="inodes-and-system-calls">Inodes and System Calls</a></h1>
<p>In this exercise we will look under the hood of the <code>stat</code> system call, which returns information about an inode.</p>
<p><em>Note: for this exercise it's even more important than usual that you are using Alpine linux in the emulator, as you will get different results if you try it on Windows Subsystem for Linux or on a Mac for example.</em></p>
<p>A system call is a way for a linux user or program to interact with the kernel, and there are usually at least three ways of calling each one:</p>
<ol>
<li>Execute the system call directly in assembly.</li>
<li>Use the wrapper function provided by your C library.</li>
<li>Use a command-line program provided by your distribution.</li>
</ol>
<h2><a class="header" href="#preparation" id="preparation">Preparation</a></h2>
<p>Install the <code>musl-dev</code> package, which provides the header files for the C library, as well as <code>gcc</code> if you have not installed that yet.</p>
<p>Have a look at the manual page <code>man stat</code> for the <code>stat</code> system call. The abbreviated headers are:</p>
<pre><code class="language-C">#include &lt;sys/stat.h&gt;

int stat(const char *pathname, struct stat *statbuf);
int fstat(int fd, struct stat *statbuf);
int lstat(const char *pathname, struct stat *statbuf);
</code></pre>
<p><code>stat</code> is the main system call: you give it a pathname and it fills a <code>struct stat</code> for you with information about the inode associated with this pathname, however if the pathname is a symbolic link then it follows the link and returns information about the target inode. If you do not want this behaviour, you can use <code>lstat</code> instead.</p>
<p><code>fstat</code> takes an open file descriptor instead of a file name: this is fine for getting the inode information (in the kernel, a file descriptor contains an inode number) but you will not be able to get a file name back from this - remember, <em>files don't have names; names have files</em>.</p>
<p>Later in the manual page, it explains the <code>struct stat</code> contents. Let's have a look at the sources directly though:</p>
<ul>
<li><code>nano /usr/include/sys/stat.h</code> shows you the header file and the function definitions, including the bitmasks for the mode bits e.g. <code>#define S_IRUSR 0400</code> is the &quot;user can read&quot; bit and the file type bits e.g. <code>#define S_IFDIR 0040000</code>. Note, in C, numbers with a leading 0 are octal!</li>
<li>The definition of the <code>struct stat</code> is in another file included from <code>sys/stat.h</code>, namely <code>bits/stat.h</code>; open that in your editor too and have a look at it.</li>
<li>The types of the fields in the structure (<code>dev_t</code>) etc. are yet in another file - <code>bits/alltypes.h</code> if you're curious - but eventually they get defined as <code>long</code>, through intermediate definitions of <code>_Int64</code> etc. Basically, on a 64-bit machine, most of these fields are 64 bits.</li>
</ul>
<p>Run the following short C program to check the size of your <code>struct stat</code>; I get 144 bytes but note down if you get something different:</p>
<pre><code class="language-C">#include &lt;sys/stat.h&gt;
#include &lt;stdio.h&gt;
int main() {
    printf(&quot;Size: %lu bytes\n&quot;, sizeof(struct stat));
    return 0;
}
</code></pre>
<h2><a class="header" href="#the-assembly-level" id="the-assembly-level">The assembly level</a></h2>
<p>Create a file with the following content - the convention for assembly files is usually to end in <code>.s</code>, so I've called mine <code>dostat.s</code>:</p>
<pre><code class="language-asm">.section .text
.global  _start

_start:
    mov $6,  %rax
    lea str, %rdi
    lea buf, %rsi
    syscall

    mov $60, %rax
    mov $0,  %rdi
    syscall

str: .asciz &quot;/dev/stdin&quot;

.section .data
buf: .skip 144
</code></pre>
<p>Change the 144 in the last line if you got a different size for your structure.</p>
<p>Let's see what's going on here:</p>
<ol>
<li><code>.section .text</code> is an assembly directive to say <em>the following is code</em>, more precisely <em>it goes in the code section (which we named 'text' for obscure historical reasons)</em>.</li>
<li><code>.global _start</code> says to export the label <code>_start</code> to the linker, which is the assembly version of <code>main</code>: in fact, C programs really start at <code>_start</code> too as you can check by setting a breakpoint on this label in a debugger, this function is part of the C library and it sets a few things up and then calls <code>main</code>. When you return from <code>main</code>, then <code>_start</code> does some cleanup and exits the program cleanly with the correct return value.</li>
<li>The way you invoke a system call is you put the system call number in the <code>rax</code> register, and parameters according to the platform convention - on Intel/AMD 64 bit, the first parameter goes in the <code>rdi</code> register, the second one in the <code>rsi</code> register. System calls and their parameters are documented <a href="https://blog.rchapman.org/posts/Linux_System_Call_Table_for_x86_64/">in this table</a> for example. Return values from system calls end up in the <code>rax</code> register again. Looking ahead a bit in our assembly code, system call 60 is <code>sys_exit</code> and takes an exit code in <code>rdi</code>, so the lines <code>mov $60, %rax; mov $0,  %rdi; syscall</code> are the equivalent of <code>return 0;</code> in a main function of a C program or <code>exit(0);</code> anywhere else (indeed, that is the last thing the C library <code>_start</code> will do when <code>main</code> returns to it).</li>
<li>System call 6 is <code>sys_lstat</code>, so the lines <code>mov $6,  %rax; lea str, %rdi; lea buf, %rsi; syscall</code> call <code>sys_lstat(str, buf)</code> where both <code>str</code> and <code>buf</code> are pointers. (<code>lea</code> stands for <em>load effective address</em> and is similar to the <code>&amp;var</code> address-of operator in C).</li>
<li><code>syscall</code> is an assembly instruction that hands control over to the operating system. It is comparable to a software interrupt as you might have learnt in Computer Architecture, but it is an optimised version (since many programs do a lot of system calls) that doesn't have the full overhead of the older interrupt mechanism on x86.</li>
<li><code>.asciz</code> is a zero-terminated string in C style (which is what the kernel expects). <code>.section .data</code> says <em>the following goes in the data section</em>, which we need because the buffer variable needs to be written to and the code section is read-only when a program is running. <code>.skip</code> reserves a block of the given size in bytes, similar to <code>byte buf[144];</code> in C (you can read <code>char</code> for <code>byte</code> if you want).</li>
</ol>
<p>Assemble the program with</p>
<ul>
<li><code>as dostat.s -g -o dostat.o</code></li>
<li><code>ld dostat.o -o dostat</code></li>
</ul>
<p>The first command is the assembler itself, which produces and object file (C compilers usually do this too, but you don't see it unless you ask for it). <code>-g</code> is the same as for gcc, it includes debug information. <code>ld</code> is the linker which produces an executable.</p>
<p>You can run the program with <code>./dostat</code>, but it will simply exit with status 0. What we want to do is debug it with <code>gdb dostat</code> (install <code>gdb</code> with <code>apk</code> if you don't have it installed already), then do the following:</p>
<ul>
<li><code>break _start</code> to set a breakpoint.</li>
<li><code>run</code> to start running (and hit the breakpoint).</li>
<li><code>si</code> steps a single assembly instruction. Do this until you have passed the first <code>syscall</code> and land on the line <code>mov $60, %rax</code>.</li>
<li>The memory at <code>buf</code> now contains filled-in <code>struct stat</code> for <code>/dev/stdin</code>, the standard input file. Look at this with <code>x/40xb &amp;buf</code> (memory dump, show 40 hex bytes starting at the buffer).</li>
</ul>
<p>Based on what you know about the <code>struct stat</code> memory layout, what is the inode number and mode of <code>/dev/stdin</code>? Note down the inode number in decimal, and the low 16 bits of the mode word in binary. Note that the memory layout is most likely little-endian, and you are working with 64-bit long integers.</p>
<p>From this information, and the bit patterns in <code>/usr/include/sys/stat.h</code>, decode the file type and permissions of <code>/dev/stdin</code>.</p>
<p>You can then quit gdb with <code>q</code>, and answer yes when it askes whether you want to terminate the program.</p>
<h2><a class="header" href="#the-c-level" id="the-c-level">The C level</a></h2>
<p>We will now do the same in C. Create this program, I've called it <code>exstat.c</code>, then compile and run it:</p>
<pre><code class="language-C">#include &lt;sys/stat.h&gt;
#include &lt;stdio.h&gt;

int main() {
    struct stat buf;
    char *str = &quot;/dev/stdin&quot;;
    int r = lstat(str, &amp;buf);
    if (r != 0) {
        puts(&quot;An error occurred.&quot;);
        return 1;
    }
    printf(&quot;The inode number is %lu.\n&quot;, buf.st_ino);
    if (S_ISDIR(buf.st_mode)) { puts(&quot;It's a directory.&quot;);}
    if (S_ISCHR(buf.st_mode)) { puts(&quot;It's a character device.&quot;);}
    if (S_ISBLK(buf.st_mode)) { puts(&quot;It's a block device.&quot;);}
    if (S_ISREG(buf.st_mode)) { puts(&quot;It's a regular file.&quot;);}
    if (S_ISFIFO(buf.st_mode)) { puts(&quot;It's a FIFO.&quot;);}
    if (S_ISLNK(buf.st_mode)) { puts(&quot;It's a soft link.&quot;);}
    if (S_ISSOCK(buf.st_mode)) { puts(&quot;It's a socket.&quot;);}

    return 0;
}
</code></pre>
<p>Here we can see that we:</p>
<ol>
<li>Set up the buffer structure and execute the system call.</li>
<li>Check the return value! If it's not 0, then an error occurred - the file <code>/usr/include/bits/errno.h</code> contains a table of error codes, although the system call will return the negative error code in register <code>rax</code>. The <code>man stat</code> manual page explains the meaning of each error code for this particular system call.</li>
<li>Print the inode number (in decimal) and the file type.</li>
</ol>
<p>Check that you get the same inode number and file type as you did with the assembly version.</p>
<h2><a class="header" href="#symbolic-links" id="symbolic-links">Symbolic links</a></h2>
<p>The point of checking the file type is that <code>/dev/stdin</code> is a symbolic link. To find out where it points, you can use this function:</p>
<pre><code class="language-C">#include &lt;unistd.h&gt;
ssize_t readlink(const char *pathname, char *buf, size_t bufsiz)
</code></pre>
<p>This is another system call wrapper (readlink is system call 89) which takes the pathname of a symbolic link and writes its contents (e.g. the file it points at) in a buffer. However, be aware of the following:</p>
<ul>
<li><code>readlink</code> does not zero-terminate its buffer! That is your responsibility as caller.</li>
<li>The returned value (yet another unsigned long) indicates what happened:
<ul>
<li>A positive value indicates the number of bytes written, so you know where to put the zero byte at the end.</li>
<li>If the return value is equal to the buffer size, then your buffer was too short, and the buffer may contain a truncated string.</li>
<li>If the return value was negative, then an error occurred.</li>
</ul>
</li>
</ul>
<p>In the assembly version, the negative error code would land directly in <code>rax</code>. This is why system calls return negative error codes, to distinguish them from successful return values as a successful call will never write a negative number of bytes.</p>
<p>However, the C wrapper is different as you can read in <code>man readlink</code>: it always returns -1 on error, but puts the error code (this time positive again) in a global variable called <code>errno</code>. You can match this against the codes in <code>errno.h</code> as before, and then check the manual page for an explanation of each one for this particular system call.</p>
<p><strong>Exercise</strong>: write a C program that, starting with a filename you pass in <code>argv[1]</code>:</p>
<ol>
<li><code>lstat</code>s the file and prints the inode number and file type of the file.</li>
<li>If the file is a symbolic link, calls <code>readlink</code> to get the link target and repeats from 1. for the target file.</li>
</ol>
<p>Since this is systems programming, make sure you check the return value of system calls, and correctly zero-terminate strings. If a system call fails, your program should print an error message and exit, and <em>never</em> look at the buffer or string the system call wrote to, as it might not contain valid data.</p>
<p>Call your program for <code>/dev/stdin</code> and <code>/dev/stdout</code> to follow the chain of soft links for these files. Also try it on a few standard files and directories (including soft links).</p>
<h2><a class="header" href="#on-the-command-line" id="on-the-command-line">On the command line</a></h2>
<p>To check the results of your program, the <code>stat</code> command line program (<code>/bin/stat</code>, in fact yet another soft link to busybox) calls stat and prints the output to the terminal. You can see with <code>stat --help</code> that it offers lots of custom formats.</p>
<p>Note that the <code>stat</code> command line tool calls the <code>lstat</code> system call by default, e.g. it does not follow soft links. <code>stat -L</code> gets you the link-following version.</p>
<p>To see how the command line version works, we are going to have a look at its sources.</p>
<p>Clone the busybox repository with <code>git clone git://busybox.net/busybox.git</code> (if that doesn't work for some reason, try the https version). Inside the cloned folder, the source file is <code>coreutils/stat.c</code> - open that and have a look:</p>
<ul>
<li>The comments at the start are read by a custom build tool. The <code>//applet</code> line (currently line 38) says to build a command called <code>stat</code>.</li>
<li><code>file_type</code> (line 123 at the time of writing) is the code for turning mode bits into strings, note there are lots of <code>#ifdef</code>s depending on what options you compile busybox with. Also, if you <code>stat</code> a file that does not match any known type, you get the string &quot;weird file&quot;.</li>
<li>Most of the source file is the kind of &quot;plumbing&quot; that you need in any real C program. The interesting part is <code>do_stat</code> (line 588 at the time of writing):</li>
</ul>
<p>First, it allocates a <code>struct stat</code> buffer like we did before. </p>
<p>The key line is currently line 605 and following:</p>
<pre><code class="language-C">if ((option_mask32 &amp; OPT_DEREFERENCE ? stat : lstat) (filename, &amp;statbuf) != 0) {
    bb_perror_msg(&quot;can't stat '%s'&quot;, filename);
    return 0;
}
</code></pre>
<p>Based on the value of <code>OPT_DEREFERENCE</code> (the <code>-L</code> command line flag), we call either the <code>stat</code> or <code>lstat</code> system call wrapper in the C library, and complain and exit if we don't get a success return value - remember, in case of errors, <code>struct stat statbuf</code> could be corrupted so we shouldn't look at it.</p>
<p>The rest of the function is basically setting up one giant <code>printf</code> statement to output the results in the correct format. Note here that the <code>struct stat</code> still doesn't know anything about the file's name, as that's not in the inode, but the command-line program does because you gave the name as an argument. </p>
<p>If the file is a soft link, then we call a version of readlink - currently <code>xmalloc_readlink_or_warn</code> in line 713 - to display the link target. This function is implemented in <code>libbb/xreadlink.c</code> where it currently delegates to <code>xmalloc_readlink</code> on line 20, which calls <code>readlink</code> in a loop with increasing buffer sizes until it finds one that is big enough for the target - have a look at how this is implemented.</p>
<p>The main function for this utility is <code>stat_main</code>, currently on line 757. All this does is parse the command line arguments with <code>getopt32</code>, call the <code>do_stat</code> function in a loop for each command line argument (lines 787 and following in the current version) and then return success if all files were successfully processed, otherwise failure.</p>
<p>If nothing else, the learning point of this activity is that system programming in C and calling syscalls directly is a lot more involved than you may think! Please don't be that kind of programmer who <a href="https://rachelbythebay.com/w/2014/08/19/fork/">ignores system call error values, and makes terrible things happen</a>.</p>
<p>If you want to explore this code further, you can build your own busybox - install <code>ncurses</code> and <code>linux-headers</code>, then run <code>make menuconfig</code> to bring up a configuration menu (this is the part that uses ncurses, which is the menu system) and just select exit (with TAB then ENTER). Then you can <code>make</code> the whole thing.</p>
<h1><a class="header" href="#shell-scripting" id="shell-scripting">Shell Scripting</a></h1>
<p>Shell scripting is a huge topic - the shell is a full programming language after all.
In the video for this activity you have only seen a very brief introduction.</p>
<h2><a class="header" href="#compile-helper-exercise" id="compile-helper-exercise">Compile helper exercise</a></h2>
<p>Write a shell script in a file called <code>b</code> (for build) that does the following:</p>
<ul>
<li>Your script should run under any Bourne-compatible shell (e.g. not just <code>bash</code>), and it should be written so that you can call it with <code>./b</code>.</li>
<li><code>./b compile NAME</code> should compile the file of the given name, so for example <code>./b compile hello</code> should run <code>gcc -Wall -std=c11 -g hello.c -o hello</code>.</li>
<li>However, your script should accept both <code>./b compile hello</code> and <code>./b compile hello.c</code> as input, and do the same thing in both cases, namely compile <code>hello.c</code>. The output file for gcc in both cases should be called just <code>hello</code>.</li>
<li>If the source file you provided as an argument does not exist (adding <code>.c</code> if necessary) then the script should print an error message and return a nonzero exit status - <em>not</em> invoke the C compiler.</li>
<li><code>./b run NAME</code> should run the program, assuming it exists in the current folder, so both <code>./b run hello</code> and <code>./b run hello.c</code> should run <code>./hello</code>. If it does not exist, again print an error message and exit with a nonzero status, don't try and run the program.</li>
<li><code>./b build NAME</code> should first compile the C source file, and then if the compile was successful it should run the program. If the compile failed, it should not try and run the program.</li>
<li>If you call <code>./b</code> without any parameters, or <code>./b COMMAND</code> with a command other than compile or run or build, it should print some information on how to use it. If you call <code>./b compile</code> or another command with no filename at all, then the script should print an error message and exit with a nonzero exit status.</li>
</ul>
<p>You now have a useful tool for when you are developing C programs. Of course you can add other features of your own like a <code>debug</code> command that compiles the file and launches it in <code>gdb</code>.</p>
<p><em>If you already know about makefiles, you might wonder why we don't just use <code>make</code> for this. You are correct, but this is specifically a shell scripting exercise. We will learn about makefiles soon.</em></p>
<h2><a class="header" href="#strict-mode" id="strict-mode">Strict Mode</a></h2>
<p>Some programming languages have an optional <em>strict mode</em> which treats some constructs as errors that people often do by mistake. It is similar in spirit to <code>-Werror</code> in C that treats all warnings as errors. <a href="http://redsymbol.net/articles/unofficial-bash-strict-mode/">This page</a> suggests using the following line near the top of your shell scripts: <code>set -euo pipefail</code>. (It also talks about IFS to improve string handling with spaces, but that's a separate matter.)</p>
<p>You might want to use these yourself if you get into shell scripting. <code>set</code> is a shell internal command that sets shell flags which controls how commands are run.</p>
<ul>
<li><code>set -e</code> makes the whole script exit if any command fails. This way, if you want to run a list of commands, you can just put them in a script with <code>set -e</code> at the top, and as long as all the commands succeed (return 0), the shell will carry on; it will stop running any further if any command returns nonzero. It is like putting <code>|| exit $?</code> on the end of every command.</li>
<li><code>set -u</code> means referencing an undefined variable is an error. This is good practice for lots of reasons.</li>
<li><code>set -o pipefail</code> changes how pipes work: normally, the return value of a pipe is that of the <em>last</em> command in the pipe. With the <code>pipefail</code> option, if any command in the pipeline fails (non-zero return) then the pipeline returns that command's exit code.</li>
</ul>
<p>A couple of notes on <code>set -u</code>: if you write something like <code>rm -rf $FOLDER/</code> and <code>$FOLDER</code> isn't set, then you don't accidentally end up deleting the whole system! Of course, most <code>rm</code> implementations will refuse to delete <code>/</code> without the <code>--no-preserve-root</code> option, and you should not have that trailing slash in the first place. There was a <a href="https://drj11.wordpress.com/2015/01/20/steaming/">bug in a beta version of Steam for linux</a> where it tried to do <code>rm -rf &quot;$STEAMROOT/&quot;*</code> to delete all files in a folder (which explains the slash), but the variable in some cases got set to the <em>empty string</em>, which <code>-u</code> would not protect against. This was an installer script, so it ran as root which made things even worse.</p>
<p><strong>Exercise</strong>: think of an example in a shell script where <code>pipefail</code> makes a difference, that is where the last command in a pipe could succeed even if a previous one fails. As a counter-example, <code>cat FILE | grep STRING</code> would fail even without <code>pipefail</code> if the file does not exist, because grep would immediately get end-of-file on standard input.</p>
<h1><a class="header" href="#activity-4" id="activity-4">Activity 4</a></h1>
<h2><a class="header" href="#videos-3" id="videos-3">Videos</a></h2>
<table><thead><tr><th>Video</th><th align="right">Length</th><th>Mediasite</th><th>Slides</th></tr></thead><tbody>
<tr><td><a href="https://ams-hsta-ims-ond.mediasite.com/MediasiteDeliver/vol01/bristoluniversity/MP4Video/e5f9f31d-d6b1-44c6-8ba9-3bea3637fc94.mp4/QualityLevels(698000)">The TTY, part 1</a></td><td align="right">29 minutes</td><td><a href="https://mediasite.bris.ac.uk/Mediasite/Play/ed98603ce01b43aaadb7c45386af1a8f1d">mediasite</a></td><td><a href="act4//COMS10012/slides/TTY.pdf">slides</a></td></tr>
<tr><td><a href="https://ams-hsta-ims-ond.mediasite.com/MediasiteDeliver/vol01/bristoluniversity/MP4Video/302f4e9c-c1bc-4200-ae5c-f9fde30ccadb.mp4/QualityLevels(698000)">The TTY, part 2</a></td><td align="right">23 minutes</td><td><a href="https://mediasite.bris.ac.uk/Mediasite/Play/e802738b6fd44a9eb753446da4a0c0401d">mediasite</a></td><td><a href="act4//COMS10012/slides/TTY2.pdf">slides</a></td></tr>
<tr><td><a href="https://ams-hsta-ims-ond.mediasite.com/MediasiteDeliver/vol01/bristoluniversity/MP4Video/c7031bf2-3ecf-41cb-a179-29e110736492.mp4/QualityLevels(698000)">The TTY, part 3</a></td><td align="right">30 minutes</td><td><a href="https://mediasite.bris.ac.uk/Mediasite/Play/031a53c97f5a493eb57969b511a5f70c1d">mediasite</a></td><td><a href="act4//COMS10012/slides/TTY3.pdf">slides</a></td></tr>
</tbody></table>
<h2><a class="header" href="#exercises-3" id="exercises-3">Exercises</a></h2>
<ul>
<li><a href="act4/./concurrent.html">Concurrent programming in POSIX</a></li>
<li><a href="act4/./cpipe.html">Pipes in C</a></li>
<li><a href="act4/./c_io.html">Input/Output in C</a></li>
<li><a href="act4/./posix_io.html">Input/Output in POSIX</a></li>
<li><a href="act4/./final.html">The final challenge</a></li>
</ul>
<h1><a class="header" href="#concurrent-programming-in-posix" id="concurrent-programming-in-posix">Concurrent programming in POSIX</a></h1>
<p>In your second year, you will study concurrent programming using the go programming language, which provides an abstraction called <em>channels</em> that different <em>actors</em> can use to talk to each other. In the case of go, the actors are threads, but the same principle applies to a concurrent system with different processes, in which case channels are a kind of <em>inter-process communication (IPC)</em>. In POSIX, pipes are a kind of channel.</p>
<ul>
<li>If one process reads from a pipe, then this blocks the process until another process writes to it.</li>
<li>If one process writes to a pipe, then this blocks the process until another process reads from it.</li>
<li>If one process reads from a pipe and another process writes to it (it does not matter who goes first) then the data is transferred from the reader to the writer, and both processes continue.</li>
</ul>
<p>For example, when you to a command like <code>cat logfile | grep Error | wc -l</code> to count the number of lines containing the word &quot;Error&quot;, then there are three processes (not counting the terminal) and two pipes involved:</p>
<p><img src="act4/../resources/pipe1.png" alt="pipe diagram" /></p>
<p><em>In this diagram, green boxes are processes with standard input on the left and standard output (top) and standard error (bottom) on the right. The little squares all represent file descriptors; a pipe has two of them, one each for reading and writing.</em></p>
<p>This is not yet a fully concurrent system though, as data is only flowing in one direction: there are no loops.</p>
<p>As a little example of something that does have a loop, we are going to use the <code>bc</code> calculator program, which reads a line from standard input, evaluates it as a formula, and writes the result to standard output:</p>
<pre><code>alpine$ bc
(you type ) 2+3
(bc prints) 5
(you type ) 1+1
(bc prints) 2
</code></pre>
<p><code>bc</code> reads in a loop, so type <code>^D</code> to close its standard input, then you get back to the terminal.</p>
<p>As a diagram, the interaction with bc looks like this:</p>
<p><img src="act4/../resources/pipe2.png" alt="pipe diagram of terminal interaction" /></p>
<p><em>Here the terminal's right file descriptor is the one that the terminal reads, and the left one is where the terminal writes your keyboard input. But there's still a human in the loop here.</em></p>
<p>We are going to write a program that can talk to <code>bc</code>. This means we have two processes, our program and <code>bc</code>, and they need to communicate with each other. We will use pipes for this, giving the following diagram where we call the pipes <em>up</em> and <em>down</em>:</p>
<p><img src="act4/../resources/pipe3.png" alt="pipe digram for a program controlling bc" /></p>
<p><em>In this diagram, data flows through pipes from left to right, but logically the &quot;down&quot; pipe is for data flowing from our program downwards to bc, and the &quot;up&quot; pipe is for data flowing back up again. Standard error is not shown (it still goes to the terminal).</em></p>
<p>The <code>bc</code> program does not need to know about any of this: it still reads expressions from its standard input, evaluates them, and writes them to standard output.</p>
<p>Notice that when we used a pipe character <code>|</code> in the shell, it automatically set up the pipes for us so each pipe had one reader and one writer. When we set the pipes up ourselves, we will have to take care of this ourselves too.</p>
<h2><a class="header" href="#the-first-program" id="the-first-program">The first program</a></h2>
<p>Study the following program. It tries to add the numbers from 1 to 10 by writing the sums (1+2 etc.) to standard output, and reading the result back from standard input. You can compile it with <code>gcc -std=c99 -Wall ipc1.c -o ipc1</code> and then run it yourself: it prints <code>1+2</code> and if you reply <code>3</code>, it follows up with <code>3+3</code> and so on. After ten steps, it prints the result and exits.</p>
<pre><code class="language-c">/* ipc1.c */
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;errno.h&gt;
#include &lt;stdlib.h&gt;

void check(int ok, char *where) {
  if (ok &lt; 0) {
    fprintf(stderr, &quot;Error in %s: %s\n&quot;, where, strerror(errno));
    exit(1);
  }
}

int evaluate(char *buffer, int len) {
  fprintf(stderr, &quot;&gt; %s&quot;, buffer);

  int ok = printf(&quot;%s&quot;, buffer);
  if (ok &lt; 0) {
    return -1;
  }
  char* p = fgets(buffer, len, stdin);
  if (p == NULL) {
    return -1;
  }
  fprintf(stderr, &quot;&lt; %s&quot;, buffer);
  return 0;
}

int main() {
  char buffer[100];
  int ok;

  setbuf(stdout, NULL);
  setbuf(stdin, NULL);

  strcpy(buffer, &quot;1+2\n&quot;);

  ok = evaluate(buffer, sizeof(buffer));
  check(ok, &quot;I/O&quot;);
  
  for (int i = 3; i &lt;= 10; i++) {
    sprintf(buffer + strlen(buffer) - 1, &quot;+%u\n&quot;, i);
    ok = evaluate(buffer, sizeof(buffer));
    check(ok, &quot;I/O&quot;);
  }
  fprintf(stderr, &quot;The result is %s&quot;, buffer);
  return 0;
}
</code></pre>
<p>The program also prints a copy of all its input and output to standard error so you can see what data is being transferred. The transfer happens in <code>evaluate</code>:</p>
<ol>
<li>First, it prints the buffer to standard error.</li>
<li>Then, it prints the buffer to standard output with printf. Checking the return value of printf is extremely paranoid, but we're about to use the program in a situation where standard output is not the terminal, so it could potentially fail.</li>
<li>Next, it reads a line from standard input with fgets. Checking the return value here is good practice even if you're not paranoid.</li>
<li>Finally, it prints the received value to standard error - note that if <code>fgets</code> had returned NULL, then it would not be safe to access the buffer.</li>
</ol>
<p>Once you are familiar with how the program works, you can comment out the lines that print to standard error if you like and run it again to see exactly what happens on standard input/output and nothing else. Then, uncomment the lines again.</p>
<div class="advanced container">
<header><span class="advanced-title"></span></header>
<div class="container-content">
<p>You could also use another trick to disambiguate standard output/error (for programs that don't, like this one, indicate which is which: the lines starting <code>&gt;</code> or <code>&lt;</code> are standard error).</p>
<pre><code class="language-sh">escape=$(printf '\033')
./ipc 2&gt; &gt;(sed -e &quot;s/\(.*\)/${escape}[32m\1${escape}[0m/&quot;)
</code></pre>
<p>This might mess up the last line on your terminal a bit, but you can reset it with Control+L.
The first command sets a shell variable to the ANSI escape character. The second line redirects standard error (<code>2&gt;</code>) to a subprocess (<code>&gt;(...)</code>) which calls the stream editor <code>sed</code> to replace each line with the line surrounded by <code>\e[32m</code> (set colour to green) and <code>\e[0m</code> (reset colour). This will make the standard error lines appear in green. </p>
<p>Incidentally, some versions of sed support the <code>\e</code> escape sequence directly, or at least the version <code>\x1b</code> that creates a character from its ASCII code in hexadecimal, but alpine's sed does not so you need the shell variable trick with a fall back to octal (033) notation!</p>
</div>
</div>
<p>And now for the interesting part:</p>
<ul>
<li>Make two named pipes (FIFOs) with <code>mkfifo up</code> and <code>mkfifo down</code>.</li>
<li>You will need two terminals open for the following. Either ssh into your alpine machine a second time or, better still, use tmux (<code>Control+B, %</code> opens a second terminal beside the first one; you can use <code>Control+B, Left</code> and <code>Control+B, Right</code> to switch between them).</li>
<li>Run the program with <code>./ipc1 &gt; down &lt; up</code> to redirect standard input and output to the pipes. This blocks (exercise: which statement is it currently blocking on?).</li>
<li>In the second terminal, run <code>bc &lt; down &gt; up</code>.</li>
</ul>
<p>Both processes should now terminate, and although you won't see the pipes directly, standard error of your program is printing a copy to the terminal, where <code>&gt;</code> is data sent to down pipe and <code>&lt;</code> is data received on the up pipe:</p>
<pre><code>&gt; 1+2
&lt; 3
&gt; 3+3
&lt; 6
&gt; 6+4
&lt; 10
...
&gt; 45+10
&lt; 55
The result is 55
</code></pre>
<p>Note that the program printed the &quot;The result is ...&quot; line to standard error too, otherwise you would not see it here.</p>
<h2><a class="header" href="#pipes-in-c" id="pipes-in-c">Pipes in C</a></h2>
<h2><a class="header" href="#types-of-inter-process-communication" id="types-of-inter-process-communication">Types of inter-process communication</a></h2>
<p>You can use any of the following for one process to talk to another:</p>
<ul>
<li>Pipes in the shell, e.g. <code>cat FILE | grep STRING</code>. We are going to learn how to manage these pipes ourselves from a C program.</li>
<li>Named pipes (FIFOs), which are pipes that have filenames.</li>
<li><code>popen</code>, a C function that launches a new process with a pipe either for reading or writing, but not both.</li>
<li>TTYs, as explained in the lectures. The C interface for using TTYs starts with <code>posix_openpt()</code> and is fairly complicated.</li>
<li>Sockets. This includes both network sockets (TCP) and also UNIX sockets, which are another type of special file. Unlike pipes, sockets provide bidirectional communication.</li>
</ul>
<p>We are going to be using pairs of pipes, since a single pipe only works in one direction.</p>
<h2><a class="header" href="#c-functions" id="c-functions">C functions</a></h2>
<p>We will need the following functions for our task, all from <code>unistd.h</code>:</p>
<ul>
<li><code>int pipe(int fd[2])</code> creates a pipe. It takes an array of two integers and creates two file descriptors in them, one for the reading and one for the writing end of the pipe. Details in <code>man 2 pipe</code>, and like all system calls, you need to check the return value and look at <code>errno</code> if it is negative.</li>
<li><code>int dup2(int oldfd, int newfd)</code> changes <code>newfd</code> to point to the same file descriptor as <code>oldfd</code>. This is the system call version of the shell redirect.</li>
<li><code>pid_t fork()</code> creates a copy of the current process, and is the starting point for launching another process. Once you are sure that it has not returned an error, then the child process will see return value 0 and the parent process will see a return value &gt;0, which is the process id of the child process.</li>
<li><code>int execve(const char *path, char *const argv[], char *const envp[])</code> replaces the current process by the indicated process, this is the C version of typing a shell command except that (1) the shell does fork-then-exec and (2) there is no shell involved, so you cannot use shell features like <code>*</code> expansion or builtin commands like cd here.</li>
</ul>
<p>Here is the basic way to launch a program from another, keeping the original program running:</p>
<pre><code class="language-C">/* launch.c */
#include &lt;unistd.h&gt;
#include &lt;stdio.h&gt;
#include &lt;errno.h&gt;
#include &lt;string.h&gt;

char* command = &quot;/bin/echo&quot;;
char* argv[] = {&quot;echo&quot;, &quot;Hello&quot;, NULL};
char* envp[] = {NULL};
/* both argv and envp must be NULL-terminated arrays,
   also argv[0] has to be the program name (busybox cares about this)
 */

int main() {
    int ok = fork();
    if (ok &lt; 0) {
        printf(&quot;fork() failed: %s\n&quot;, strerror(errno));
        return 1;
    }
    /* ok, fork succeeded and the following code will now be running TWICE */
    if (ok == 0) {
        /* This is the child process */
        ok = execve(command, argv, envp);
        if (ok &lt; 0) {
            printf(&quot;execve() failed: %s\n&quot;, strerror(errno));
            return 1;
        }
        /* we will never get here as if execve succeeded, we're gone */
    }
    
    /* if we got here, then we're the parent process */
    printf(&quot;Launched a child process, it has pid %u.\n&quot;, ok);
    
    return 0;
}
</code></pre>
<p>If you run this several times in a row, you might see the PID of the child increasing by 2 each time, why is this?</p>
<p>And here is the basic way to work with pipes:</p>
<pre><code class="language-C">#include &lt;stdio.h&gt;
#include &lt;errno.h&gt;
#include &lt;string.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;

typedef int fd;
typedef fd Pipe[2];
fd Reader(Pipe p) { return p[0]; }
fd Writer(Pipe p) { return p[1]; }

void check(int ok, char *where) {
  if (ok &lt; 0) {
    fprintf(stderr, &quot;Error in %s: %s\n&quot;, where, strerror(errno));
    exit(1);
  }
}

int main() {
  int ok;
  Pipe p;
  ok = pipe(p);           check(ok, &quot;opening pipe&quot;);
  ok = close(Reader(p));  check(ok, &quot;closing reader&quot;);
  /* here we can write to p */
  ok = close(Writer(p));  check(ok, &quot;closing writer&quot;);
  return 0;
}
</code></pre>
<p>Let's go through this step by step.</p>
<ul>
<li>A file descriptor is simply an integer. so we make a typedef for this.</li>
<li>A pipe is a pair of file descriptors for reading and writing, implemented as an array of length 2. The second typedef is C syntax for defining <code>Pipe</code> with a capital P to be <code>fd[2]</code> We use a capital P because lowercase <code>pipe</code> is already in use for the function that sets up a pipe.</li>
<li>The functions <code>Reader</code> and <code>Writer</code> are just for convenience.</li>
<li>In main, we declare a variable of type <code>Pipe</code> and open it with <code>pipe()</code>. Like all POSIX functions this returns a negative number in case of errors, and we have to check for this: it's not safe to use the pipe if it was not opened correctly. The pipe does not need a name as it's local to our program, but you can print the value of the integers if you like, it should be something like (3, 4) as 0-2 are already in use for standard input, output and error.</li>
<li>In this example we want to use a pipe for writing to, so we close the reading end first. This is important when sharing a pipe between two processes: only one process should have each end open. (There are scenarios where you might want both ends of a pipe open in the same process, but they are more advanced than what we are doing here.)</li>
<li>In the line where the comment is, we can write to the pipe - you will see how soon.</li>
<li>Finally, before returning, we close the writing end of the pipe to ensure the process on the other end knows we're done: if we don't do this, they could get a &quot;broken pipe&quot; (EPIPE) error.</li>
</ul>
<p>We still need to learn how to write to a file descriptor, though. And this pipe won't do anything useful until we can connect something to the other end.</p>
<div class="advanced container">
<header><span class="advanced-title"></span></header>
<div class="container-content">
<p>If you look at the pattern for checking return values</p>
<pre><code>ok = pipe(p); check(ok, &quot;create pipe&quot;);
</code></pre>
<p>you might be wondering why we don't just combine it into one:</p>
<pre><code>check(pipe(p), &quot;create pipe&quot;);
</code></pre>
<p>This is absolutely fine except if we want to debug the function being called, as it makes using the debugger's step features more complicated (more on this in future weeks of this unit). It's just a personal preference of mine not to combine the two.</p>
<p>Of course, if you want to use line-based features of debuggers like breakpoints a lot, you might even want to put the check on a separate line.</p>
<p>You might have wondered if the problem with the all-in-one pattern is that it &quot;swallows&quot; the return value. That is not a problem: we could adapt <code>check</code> to return its first parameter as the return value if it's not an error, then where you do need the value you can do things like</p>
<pre><code class="language-C">int pid = check(fork(), &quot;trying to fork&quot;);
if (pid &gt; 0 ) { /* parent */ }
else { /* child */ }
</code></pre>
<p>This is one of several patterns for error handling you will see in C, although this particular one is commonly implemented as a macro so it can also print the file and line where the error occurred:</p>
<pre><code class="language-C">#define check(ok, where) _check(ok, where, __FILE__, __LINE__)
int _check(int ok, char *where, char *file, int line) {
  if (ok &lt; 0) {
    fprintf(stderr, &quot;Error at %s on line %i while %s: %s\n&quot;, 
            file, line, where, strerror(errno));
    exit(1);
  }
  return ok;
}
</code></pre>
<p>Since C99 you can also use <code>__func__</code> to get the name of the current function.</p>
<p>You will find various patterns like this a lot if you start looking into real C code bases. Of course, most real programs will try to handle an error where possible rather than just exit the whole program.</p>
</div>
</div>
<h1><a class="header" href="#inputoutput-in-c" id="inputoutput-in-c">Input/Output in C</a></h1>
<h2><a class="header" href="#reminder-c-file-handling" id="reminder-c-file-handling">Reminder: C file handling</a></h2>
<p>You should already be familiar with the following C functions from <code>&lt;stdio.h&gt;</code>, though you can look up details with <code>man 3 FUNCNAME</code> on a lab machine:</p>
<ul>
<li><code>FILE *fopen(const char *path, const char *mode)</code> opens a file, returning a file handle if successful and NULL otherwise. On some systems, it makes a difference whether you read a file in text mode (<code>r</code>) or binary mode (<code>rb</code>), the difference being that the former activates an extra &quot;line discipline&quot; in the C library. For example on Windows, text mode translates a lone <code>\n</code> character to <code>\r\n</code>. <em>On POSIX systems, there is no difference between text and binary mode.</em> </li>
<li><code>int fclose(FILE *file)</code> closes a file, and flushes any pending writes. It returns 0 on success and nonzero in case of errors.</li>
<li><code>int fflush(FILE *file)</code> flushes a file: for output, it makes sure any buffered characters are written out. For input, it throws away any unread input in the c library input buffer. It returns 0 on success and nonzero in case of errors. <code>fflush(NULL)</code> flushes all open files.</li>
<li><code>int feof(FILE *file)</code> returns nonzero if the file in question has reached end-of-file, and zero otherwise. This is the only correct way to test for an end-of file condition.</li>
<li><code>int ferror(FILE *file)</code> returns nonzero if the file in question is in an error state. For example after a <code>fread</code> that did not return the expected number of blocks, exactly one of <code>feof</code> and <code>ferror</code> will return nonzero, indicating what happened. In case of an error, the global variable <code>errno</code> will contain the error code.</li>
<li><code>size_t fread(void *dest, size_t size, size_t num, FILE *file)</code> reads up to <code>num</code> blocks of <code>size</code> bytes into the buffer at <code>dest</code> and returns the number of blocks read (for a block size of 1, this is the number of bytes). If the return value is less than <code>num</code> then either an error occurred or the end of the file was reached.</li>
<li><code>size_t fwrite(const void *buffer, size_t size, size_t num, FILE *file)</code> writes up to <code>num</code> blocks of <code>size</code> bytes from the <code>buffer</code> to the <code>file</code> and returns the number of blocks written. If this is less than <code>num</code>, then an error occurred during the writing.</li>
</ul>
<p>A number of utility functions build upon these:</p>
<ul>
<li><code>int fprintf(FILE *stream, const char *format, ...)</code> writes formatted output to a file, usually by calling <code>fwrite</code> behind the scenes. <code>printf</code> is a shortcut for <code>fprintf(stdout, ...)</code>. These functions to not print a newline unless you ask for one. It returns the number of characters written, or a negative number if an error occurred.</li>
<li><code>int fputs(const char *string, FILE *file)</code> writes a zero-terminated string to the file, not including the zero terminator. <code>puts</code> is a shortcut that writes to <code>stdout</code> <em>and</em> adds a newline at the end. </li>
<li><code>int fputc(int c, FILE *file)</code> writes a single character (<code>c</code> is cast to an <code>unsigned char</code> first) and <code>putchar</code> is a shortcut for writing to <code>stdout</code> (but does not add a newline, unlike <code>puts</code>).</li>
<li><code>int fgetc(FILE *file)</code> reads a single character from a file (but returns it as an int, however it's safe to cast to char). <code>getchar</code> is a shortcut that reads from standard input.</li>
<li><code>char *fgets(char *buffer, int size, FILE *file)</code> reads up to <code>size-1</code> bytes into the buffer, stopping early if it finds a null byte, newline or end-of-file character. It then adds a zero-terminator to the string. If it stopped early because of a newline, the newline is included in the buffer; if it stopped due to an end-of-file then this is not included. Older versions of C included a <code>gets</code> version that reads from standard input and does not take a size argument; this is insecure as it can produce a buffer overflow and it should never be used. <code>fgets</code> is safe if the length of the buffer is at least <code>size</code> bytes. It returns a pointer to buffer on success and NULL if an error occurred. End-of-file counts as an error for this purpose if no characters could be read at all.</li>
</ul>
<p>Fread (and fwrite) can return in one of three different states:</p>
<ol>
<li>The return value is equal to the number of items you asked to read/write (third argument). This means that the read/write was successful.</li>
<li>The return value is not equal to the number of items, <code>ferror</code> returns nonzero on the file: an error occurred. The return value indicates how many items were successfully read or written before the error occurred. <code>errno</code> contains more information about what happened.</li>
<li>The return value is not equal to the number of items, <code>ferror</code> returns zero on the file: end of file. Calling <code>feof</code> on the file will return nonzero. End of file when reading means exactly what it says; end of file when writing to something with a program on the other side (pipe, socket, pty) means the other side has closed the connection.</li>
</ol>
<h2><a class="header" href="#exercises-4" id="exercises-4">Exercises</a></h2>
<p>For our next exercise, we investigate how the C library file functions interact with the terminal. Compile this program:</p>
<pre><code class="language-C">// program: input1.c //
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;errno.h&gt;

// Utility function to print an error message and return from main,
// use: return error(code, text); // in main
// prints text and the current errno value, then returns code.
int error(int ret, char* text) {
  int e = errno;
  printf(&quot;Error %s: %s (code %i).\n&quot;, text, strerror(e), e);
  return ret;
}

int main(int argc, char **argv) {
    if (argc &lt; 2) { printf(&quot;Use: %s FILENAME\n&quot;, argv[0]); return 1; }
    printf(&quot;Opening [%s]\n&quot;, argv[1]);
    FILE *file = fopen(argv[1], &quot;r&quot;);
    if (file == NULL) { return error(2, &quot;opening file&quot;); }
    
    char c, d;
    size_t result = fread(&amp;c, 1, 1, file);
    if (result &lt; 1) { 
      if (ferror(file)) {
        return error(2, &quot;reading first character&quot;);
      } else {
        puts(&quot;No first character - end of file?&quot;);
        return 2;
      }
    }
    printf(&quot;Read character: [%c].\n&quot;, c);
    result = fread(&amp;d, 1, 1, file);
    if (result &lt; 1) { 
      if (ferror(file)) {
        return error(2, &quot;reading second character&quot;); 
      } else {
        puts(&quot;No second character - end of file?&quot;);
        return 2;
      }
    }
    printf(&quot;Read another character: [%c].\n&quot;, d);
    
    int e = fclose(file);
    if (e) { return error(2, &quot;closing file.&quot;); }
    return 0;
}
</code></pre>
<p>The essence of the program are the four lines</p>
<pre><code>fread(&amp;c, 1, 1, file);
printf(..., c);
fread(&amp;d, 1, 1, file);
printf(..., d);
</code></pre>
<p>which read two characters from the file indicated in its first argument, then print them out.
Note that we print the first character before reading the second, as this will become relevant.</p>
<p>The rest of the program is error handilng, and although some tutorials leave this off to make the code look easier, this sets you up for terrible habits - in the real world, errors happen and you need to handle them properly. So this program also shows the absolute minimum of error handling when you work with a file.</p>
<ul>
<li>Make a file <code>file</code> containing some characters such as <code>abc</code> and run <code>./input1 file</code>. Convince yourself that the program prints the first two characters (first two bytes, to be precise).</li>
<li>Next, run <code>./input1 /dev/stdin</code>, to make it read from standard input. Notice that it blocks.
Type a few characters such as <code>abc</code> and notice that the program prints nothing, until you press ENTER at which point both the &quot;Read character&quot; and &quot;Read another character&quot; output appears at once. <strong>What is the reason for this?</strong></li>
<li>Restart the program, and when it is waiting for input, type <code>ab[BACKSPACE]c[ENTER]</code>. <strong>Explain what you see.</strong> </li>
<li>What happens if you enter only one character and then press ENTER? What if you press ENTER and haven't typed anything at all?</li>
<li>If you want, verify that using fgetc / getchar produces the same behaviour on standard input: the program does not proceed past the first read command until you press ENTER. You can even try debugging with gdb to make sure.</li>
<li>Insert the line <code>setbuf(file, NULL);</code> just after the <code>fopen</code> line to make sure it's not the C library buffering.</li>
</ul>
<p>Have you answered the questions in bold above before reading on?</p>
<ul>
<li>Next, on your terminal, execute <code>stty -icanon</code>, which turns off the &quot;icanon&quot; setting. (The convention for <code>stty</code> is that an option name in an argument turns it on, except if prefixed with a minus which turns it off.)</li>
<li>Rerun the program (<code>./input1 /dev/stdin</code>) and see what happens now.</li>
<li>Turn &quot;icanon&quot; back on with <code>stty icanon</code>. </li>
<li>Research what <code>icanon</code> does, for example in <code>man stty</code> on a lab machine (the alpine version of the manual is less helpful) or online.</li>
<li><strong>Why does BACKSPACE and <code>^U</code> work in your bash shell, even with icanon turned off?</strong></li>
</ul>
<p>Next, we are going to experiment with the terminal in fully raw mode:</p>
<ul>
<li><code>stty -g</code> prints the current terminal setting in a format that you can save and load again. Take a look, then store them with the shell command <code>state=$(stty -g)</code>.</li>
<li>Execute <code>stty raw</code>, then run your program again. <strong>The terminal looks a bit &quot;messed up&quot; - can you tell what is happening?</strong> Try another command like <code>ls</code> in raw mode too if that helps.</li>
<li>Restore your terminal settings with <code>stty $state</code>, reading them back from the variable where you stored them. You can then reset the window with <code>^L</code>.</li>
</ul>
<p>There is an important warning here if you are ever benchmarking a program that produces (standard) output - the total running time will be the sum of the program's running time and the connected terminal's running time to process the output. For example, printing a sequence of newline characters is typically slower than printing a sequence of 'a's, even if both programs are doing <code>putc</code> in a loop, because the terminal has extra work to do on each newline.</p>
<p>Here is another C program to experiment with:</p>
<pre><code class="language-C">// input2.c //
// Reads characters in a loop and prints their hex codes. 
// Quit with 'Q'.

#include &lt;stdio.h&gt;

int main() {
  unsigned char c;
  int r;
  setbuf(stdout, NULL);
  while(1) {
    r = fread(&amp;c, 1, 1, stdin);
    if (r &lt; 1) break; // bail out on error or eof
    if (c == 'Q') break;
    printf(&quot;(%02X) &quot;, c);
  }
  return 0;
}
</code></pre>
<ul>
<li>What do you expect to happen if you run this in a &quot;normal&quot; terminal and type a few characters?</li>
<li>Run it in a terminal with icanon turned off and type a few characters. Notice that you can still cancel it with <code>^C</code>.</li>
<li>Run it in a terminal in raw mode and type a few characters. What happens now when you press <code>^C</code>?</li>
</ul>
<p>Luckily, we built in another way to quit the program with Q!</p>
<ul>
<li>In raw mode, try a few &quot;special&quot; keys such as ENTER, ESC, the arrow keys, function keys (F1, F2) etc.</li>
<li>We turned off buffering for standard <em>output</em>. Why is this important - what happens otherwise and who is doing the buffering?</li>
</ul>
<p>What actually happens when you press Control-C in a terminal in &quot;cooked&quot; mode is it sends the signal <code>SIGINT</code> (interrupt) to the connected program - the default behaviour for this signal is to terminate the program. Putting the terminal in raw mode just passes the control code for Control-C on to the program, though it would still quit if you sent it a SIGINT another way (e.g. with the <code>kill</code> command from another terminal). However, you could also write a signal handler in your own program that reacts to SIGINT and does something else, for example just ignores the signal.</p>
<p>When you type say an <code>a</code>, even in raw mode, the character appears on your screen even though there's no print command for it. This is the terminal echo; you can turn even this off with <code>stty -echo</code> but you are now typing blind! You can still start your program with <code>./input2</code> followed by ENTER, and it will still print the hex codes of everything you type from then on until you press Q but it will no longer show you the characters themselves. If you saved the terminal state before, then typing <code>stty $state</code> and ENTER will get you your echo back.</p>
<h1><a class="header" href="#inputoutput-in-posix" id="inputoutput-in-posix">Input/output in POSIX</a></h1>
<p>Both the C library and the POSIX standard library contain file I/O functions. Usually, the C library ones build on the POSIX ones if you are on a POSIX system.</p>
<p>The POSIX I/O functions are declared in <code>fcntl.h</code> and <code>unistd.h</code>. The main ones are:</p>
<h2><a class="header" href="#open-and-close" id="open-and-close">Open and Close</a></h2>
<ul>
<li><code>int open(const char *pathname, int flags, [mode_t mode])</code> opens a file and returns a file descriptor. The flags are the boolean OR (<code>|</code>) of one or more of the following:
<ul>
<li><code>O_CREAT</code>: if the file does not exist, create it. In this case the <em>optional</em> mode parameter can be used to specify the permissions for the newly created file. If the <code>O_CREAT</code> flag is omitted and the file does not exist, <code>open</code> returns an error.</li>
<li><code>O_EXCL</code>: return an error if the file already exists (only really useful together with <code>O_CREAT</code>).</li>
<li><code>O_PATH</code>: don't really open the file, just make a file descriptor (that you can use to e.g. <code>stat</code> the file). In this case you do not need one of the three flags mentioned in the next point.</li>
<li><code>O_RDONLY</code>, <code>O_WRONLY</code>, <code>O_RDWR</code>: exactly one of these mutually exclusive flags must be set to indicate whether you want read, write or both access modes on the file.</li>
<li><code>O_TRUNC</code>: if the file already exists, then its previous contents are overwritten if you open it to write.</li>
<li><code>O_NONBLOCK</code>: this is the most interesting option and the main reason why you might want to use <code>open</code> over <code>fopen</code>. More details on this in the next activity.</li>
<li>There are a lot more flags that you can see with <code>man 2 open</code>.</li>
</ul>
</li>
<li>
<ul>
<li><code>int close(int fd)</code>: close a file descriptor. Returns 0 on success and -1 (setting errno) on error.</li>
</ul>
</li>
</ul>
<p>You might wonder how a C function call can have an <em>optional</em> parameter. The function is actually declared in <code>fcntl.h</code> as <code>int open(const char*, ...)</code> where the ellipsis means <em>any number of parameters of any type</em> just like <code>printf</code> uses.</p>
<p>If <code>open()</code> fails, it returns a negative number that indicates the error code: see <code>errno.h</code> for the names of the codes and the manual page (<code>man 2 open</code>) for what each one means for this function.</p>
<h2><a class="header" href="#nonblocking-io" id="nonblocking-io">(Non)blocking IO</a></h2>
<p>When you read from a regular file, there is a short delay while the kernel does the actual reading for you - possibly it has to fetch the data from disk. This is not what is meant by blocking. However, when you read from a pipe (e.g. you call <code>a | b</code> in the shell and <code>b</code> reads from standard input) or from a named pipe (FIFO), then if no process is connected to the writing end, your system call blocks until someone writes to the pipe.</p>
<p>The Posix functions offer an option <code>O_NONBLOCK</code> that makes a call fail instead of block. This is one of the reasons that you might use <code>read</code> directly rather than <code>fread</code>. While this is an important topic for concurrent programming (and especially network programming), that can wait until second year.</p>
<h2><a class="header" href="#read-and-write" id="read-and-write">Read and Write</a></h2>
<ul>
<li><code>ssize_t read(int fd, void *buf, size_t count)</code>: read up to <code>count</code> bytes from the file descriptor <code>fd</code> into the buffer. In case of an error, this returns -1 and puts the error code in <code>errno</code>. If the end of file is reached, then the return value might be less than count (possibly zero) but this does not count as an error.</li>
<li><code>ssize_t write(int fd, const void *buf, size_t count)</code>: the same but for writing to a file (descriptor).</li>
</ul>
<p>Before you use any of these functions, there are two warnings. The small one is that unlike the C library which provides <em>buffered</em> input/output, the POSIX functions do not - so while it's ok to read a large file one character at a time with <code>fread</code> due to buffering, this becomes really inefficient if you use the basic <code>read</code>.</p>
<p>The big warning is that checking return values is even more important than usual because these functions can return two kinds of errors: fatal ones (e.g. file not found) and temporary ones, which basically means <em>try again</em>, so in some cases the correct pattern to use these functions is to call them in a loop that repeats until the function either succeeds or returns a fatal error. Specifically, <code>read()</code> can return any of the following:</p>
<ul>
<li>-1, <code>errno = EINTR</code>: the call was interrupted, try again.</li>
<li>-1, <code>errno = EAGAIN</code> or <code>errno = EWOULDBLOCK</code>: you have requested non-blocking IO, and the call would block.</li>
<li>-1, any other errno: a fatal error occurred and <code>errno</code> gives more information. You must not retry the call.</li>
</ul>
<h2><a class="header" href="#exercise" id="exercise">Exercise</a></h2>
<p>In the sources for busybox (<code>git clone git://busybox.net/busybox.git</code>), use your shell skills to find the source file and line where the function <code>safe_read</code> is defined, and study the pattern used there to operate <code>read</code> in a loop.</p>
<h2><a class="header" href="#the-final-challenge" id="the-final-challenge">The final challenge</a></h2>
<p>The final challenge for this part of the unit is to write a C program that uses pipes to interact with bc to add the numbers from 1 to 10, as an example of concurrency and inter-process communication in action. For this, you will need to put together items from the previous pages for this activity.</p>
<p>The general ideas are:</p>
<ol>
<li>Create two pipe variables called <code>up</code> and <code>down</code>.</li>
<li>Fork the process. This shares the pipes between both copies of the process.</li>
<li>The parent process will write to the down pipe and read from the up pipe, so it should close the down reader and the up writer.</li>
<li>The child process closes the down writer and the up reader, redirects its standard input to the down reader and its standard output to the up writer, and then execs <code>bc</code>. This keeps the redirected standard input and output.</li>
<li>The parent process now writes its sums starting with <code>1+2</code> to the down writer with <code>write</code> and then uses <code>read</code> on the up reader to get the result. You can use a function <code>evaluate()</code> like in the previous example that handles the reading/writing and prints debug information to standard output (we don't need standard error as the pipe is a separate file descriptor).</li>
<li>The parent cleanly closes the pipes when it is done, and writes the result to standard output.</li>
</ol>
<p>Two constraints here:</p>
<ul>
<li>All calls to Posix or file I/O functions <em>must</em> be checked for error return values. It is ok to terminate the program in case of fatal errors rather than try and fix the cause, but not to just carry on ignoring the return value. You can reuse the <code>check()</code> function for this.</li>
<li>Calls to <code>read</code> and <code>write</code> must be assumed to be able to fail with <code>EINTR</code>, in which case they need to be retried, so these functions must be called from within loops as you saw in the busybox sources.</li>
</ul>
<p>The one new function you need to know is <code>int dup2(int src, int dest)</code> which redirects the destination to be a duplicate of the source. For example if <code>dr</code> is a file decriptor for the down reader, then <code>ok = dup2(dr, 0)</code> redirects standard input (file descriptor 0) to read from the down reader. Of course, you have to check the return value <code>ok</code>!</p>
<div class="advanced container">
<header><span class="advanced-title"></span></header>
<div class="container-content">
<p>One way of using <code>dup2</code> is to redirect your own standard output to a file, then any calls to <code>printf</code> or other functions from then on should end up in the file. If you later on want to restore the original standard output, you can first call <code>int dup(int fd)</code> which makes a copy of the file descriptor - for example, if a file is open on file descriptor 3, then</p>
<pre><code class="language-C">saved = dup(1);      check(saved, &quot;duplicating standard output&quot;);
ok = dup2(3, 1);     check(ok, &quot;redirecting standard output&quot;);
/* any printf etc here will go to the file on fd 3 */
ok = dup2(saved, 1); check(ok, &quot;restoring standard output&quot;);
ok = close(saved);   check(ok, &quot;closing duplicate&quot;);
</code></pre>
<p>shows how you can restore the original standard output by making a copy. If no other file descriptors are open, then <code>saved</code> will likely have a value of 4, as file descriptors are just numbers to communicate with the kernel and the kernel usually gives you the next consecutive unused one when you open or duplicate a file descriptor.</p>
</div>
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
